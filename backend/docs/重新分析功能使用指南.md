# 重新分析功能使用指南

## 📖 概述

当代码更新后，你可以使用重新分析功能来更新分析文档，而不需要重新上传项目。

## 🚀 使用方法

### 方法 1：使用 API 接口（推荐）

**API 端点**：
```
POST /api/analysis/repository/{repository_id}/reanalyze
```

**示例**：
```bash
# 重新分析仓库 ID 为 3 的项目
curl -X POST http://localhost:8000/api/analysis/repository/3/reanalyze
```

**响应示例**：
```json
{
    "status": "success",
    "message": "重新分析任务已创建并提交到后台队列",
    "repository_id": 3,
    "task_id": 5,
    "repository_name": "codereader_workspace",
    "celery_task_id": "764346b5-56c3-4eb8-81b9-26edb0998a79"
}
```

---

### 方法 2：使用 Python 脚本

**查看所有仓库**：
```bash
cd Code-reader/backend
source .venv/bin/activate
python scripts/reanalyze_repository.py --list
```

**重新分析指定仓库**：
```bash
python scripts/reanalyze_repository.py 3
```

---

### 方法 3：使用 Python 代码

```python
from database import SessionLocal
from models import Repository, AnalysisTask
from tasks import run_analysis_task

db = SessionLocal()

# 1. 查询仓库
repository_id = 3
repository = db.query(Repository).filter(Repository.id == repository_id).first()

# 2. 创建新任务
new_task = AnalysisTask(
    repository_id=repository_id,
    status="pending",
    total_files=0,
    successful_files=0,
    failed_files=0,
    code_lines=0,
    module_count=0,
)
db.add(new_task)
db.commit()
db.refresh(new_task)

# 3. 准备仓库信息
repo_info = {
    "full_name": repository.full_name or repository.name,
    "name": repository.name,
    "local_path": repository.local_path,
}

# 4. 触发分析任务
run_analysis_task.delay(new_task.id, repo_info)

print(f"✅ 任务 {new_task.id} 已提交到 Celery 队列")

db.close()
```

---

## 📊 工作流程

重新分析会执行完整的分析流程：

1. **步骤 0**: 扫描文件，创建 FileAnalysis 记录
2. **步骤 1**: 创建向量知识库
3. **步骤 2**: 分析数据模型（异步提交文件分析任务）
4. **步骤 3**: 生成文档结构（所有文件完成后自动触发）

**特点**：
- ✅ 使用 Celery 异步任务，不阻塞 API
- ✅ 并发执行文件分析（5 个 Worker 同时处理）
- ✅ 自动触发文档生成
- ✅ 保留旧的分析结果（创建新任务）

---

## 🔍 查看进度

### 方法 1：前端查看
打开 http://localhost:3000，在任务列表中查看进度

### 方法 2：命令行查看
```bash
cd Code-reader/backend
source .venv/bin/activate

python -c "
from database import SessionLocal
from models import AnalysisTask, FileAnalysis
from collections import Counter

db = SessionLocal()

# 查询最新任务
task = db.query(AnalysisTask).order_by(AnalysisTask.id.desc()).first()
if task:
    print(f'任务 {task.id}: {task.status}')
    
    files = db.query(FileAnalysis).filter(FileAnalysis.task_id == task.id).all()
    if files:
        status_count = Counter([f.status for f in files])
        total = len(files)
        completed = status_count.get('success', 0)
        print(f'进度: {completed}/{total} ({completed*100//total if total > 0 else 0}%)')

db.close()
"
```

---

## ⚠️ 注意事项

1. **代码更新后**：确保代码已经更新到仓库路径中
2. **仓库路径**：重新分析使用的是原始仓库路径，不需要重新上传
3. **旧任务**：重新分析会创建新任务，旧任务和分析结果会保留
4. **并发限制**：Celery Worker 并发数为 5，大型项目可能需要几分钟

---

## 🐛 故障排查

### 问题 1：API 返回 404
**原因**：仓库 ID 不存在  
**解决**：使用 `--list` 查看所有仓库 ID

### 问题 2：API 返回 400
**原因**：仓库路径不存在  
**解决**：检查仓库路径是否正确

### 问题 3：任务一直是 pending
**原因**：Celery Worker 未运行  
**解决**：检查 Celery Worker 状态
```bash
pgrep -f "celery.*worker"
```

### 问题 4：文件分析进度为 0
**原因**：任务还在步骤 0-2 阶段  
**解决**：等待几分钟，步骤 2 完成后会开始文件分析

