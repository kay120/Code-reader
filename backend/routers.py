"""
APIè·¯ç”±å®šä¹‰
"""

from fastapi import APIRouter, Depends, Query, UploadFile, File, Form, BackgroundTasks, HTTPException
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from database import get_db
from tasks import analyze_single_file_task
from services import (
    FileAnalysisService,
    AnalysisItemService,
    RepositoryService,
    AnalysisTaskService,
    UploadService,
    TaskReadmeService,
)
from models import AnalysisTask, Repository, FileAnalysis
from typing import Optional, List
from pydantic import BaseModel, Field
import logging
import os
import zipfile
import tempfile
import shutil
import requests
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®logger
logger = logging.getLogger(__name__)


# Pydanticæ¨¡å‹å®šä¹‰
class RepositoryCreate(BaseModel):
    """åˆ›å»ºä»“åº“çš„è¯·æ±‚æ¨¡å‹"""

    user_id: Optional[int] = Field(default=1, description="ç”¨æˆ·IDï¼Œé»˜è®¤ä¸º1")
    name: str = Field(..., min_length=1, max_length=255, description="ä»“åº“åç§°")
    full_name: Optional[str] = Field(None, max_length=255, description="å®Œæ•´ä»“åº“å")
    local_path: str = Field(..., min_length=1, max_length=1024, description="æœ¬åœ°ä»“åº“è·¯å¾„")
    status: Optional[int] = Field(default=1, description="çŠ¶æ€ï¼š1=å­˜åœ¨ï¼Œ0=å·²åˆ é™¤")


class RepositoryUpdate(BaseModel):
    """æ›´æ–°ä»“åº“çš„è¯·æ±‚æ¨¡å‹"""

    user_id: Optional[int] = Field(None, description="ç”¨æˆ·ID")
    name: Optional[str] = Field(None, min_length=1, max_length=255, description="ä»“åº“åç§°")
    full_name: Optional[str] = Field(None, max_length=255, description="å®Œæ•´ä»“åº“å")
    local_path: Optional[str] = Field(None, min_length=1, max_length=1024, description="æœ¬åœ°ä»“åº“è·¯å¾„")
    status: Optional[int] = Field(None, description="çŠ¶æ€ï¼š1=å­˜åœ¨ï¼Œ0=å·²åˆ é™¤")


class AnalysisTaskCreate(BaseModel):
    """åˆ›å»ºåˆ†æä»»åŠ¡çš„è¯·æ±‚æ¨¡å‹"""

    repository_id: int = Field(..., description="ä»“åº“ID")
    total_files: Optional[int] = Field(default=0, description="æ€»æ–‡ä»¶æ•°")
    successful_files: Optional[int] = Field(default=0, description="æˆåŠŸåˆ†ææ–‡ä»¶æ•°")
    failed_files: Optional[int] = Field(default=0, description="å¤±è´¥æ–‡ä»¶æ•°")
    code_lines: Optional[int] = Field(default=0, description="ä»£ç è¡Œæ•°")
    module_count: Optional[int] = Field(default=0, description="æ¨¡å—æ•°é‡")
    status: Optional[str] = Field(default="pending", description="ä»»åŠ¡çŠ¶æ€ï¼špending/running/completed/failed")
    start_time: Optional[str] = Field(None, description="å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰")
    end_time: Optional[str] = Field(None, description="ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰")
    task_index: Optional[str] = Field(None, description="ä»»åŠ¡ç´¢å¼•")


class AnalysisTaskUpdate(BaseModel):
    """æ›´æ–°åˆ†æä»»åŠ¡çš„è¯·æ±‚æ¨¡å‹"""

    repository_id: Optional[int] = Field(None, description="ä»“åº“ID")
    total_files: Optional[int] = Field(None, description="æ€»æ–‡ä»¶æ•°")
    successful_files: Optional[int] = Field(None, description="æˆåŠŸåˆ†ææ–‡ä»¶æ•°")
    failed_files: Optional[int] = Field(None, description="å¤±è´¥æ–‡ä»¶æ•°")
    code_lines: Optional[int] = Field(None, description="ä»£ç è¡Œæ•°")
    module_count: Optional[int] = Field(None, description="æ¨¡å—æ•°é‡")
    status: Optional[str] = Field(None, description="ä»»åŠ¡çŠ¶æ€ï¼špending/running/completed/failed")
    start_time: Optional[str] = Field(None, description="å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰")
    end_time: Optional[str] = Field(None, description="ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰")
    task_index: Optional[str] = Field(None, description="ä»»åŠ¡ç´¢å¼•")
    current_file: Optional[str] = Field(None, description="å½“å‰å¤„ç†çš„æ–‡ä»¶")


class FileAnalysisCreate(BaseModel):
    """åˆ›å»ºæ–‡ä»¶åˆ†æè®°å½•çš„è¯·æ±‚æ¨¡å‹"""

    task_id: int = Field(..., description="åˆ†æä»»åŠ¡ID")
    file_path: str = Field(..., min_length=1, max_length=1024, description="æ–‡ä»¶è·¯å¾„")
    language: Optional[str] = Field(None, max_length=64, description="ç¼–ç¨‹è¯­è¨€")
    analysis_version: Optional[str] = Field(default="1.0", max_length=32, description="åˆ†æç‰ˆæœ¬")
    status: Optional[str] = Field(default="pending", description="åˆ†æçŠ¶æ€ï¼špending/success/failed")
    code_lines: Optional[int] = Field(default=0, description="ä»£ç è¡Œæ•°")
    code_content: Optional[str] = Field(None, description="ä»£ç å†…å®¹")
    file_analysis: Optional[str] = Field(None, description="æ–‡ä»¶åˆ†æç»“æœ")
    dependencies: Optional[str] = Field(None, description="ä¾èµ–æ¨¡å—åˆ—è¡¨")
    error_message: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")


class FileAnalysisUpdate(BaseModel):
    """æ›´æ–°æ–‡ä»¶åˆ†æè®°å½•çš„è¯·æ±‚æ¨¡å‹"""

    task_id: Optional[int] = Field(None, description="åˆ†æä»»åŠ¡ID")
    file_path: Optional[str] = Field(None, min_length=1, max_length=1024, description="æ–‡ä»¶è·¯å¾„")
    language: Optional[str] = Field(None, max_length=64, description="ç¼–ç¨‹è¯­è¨€")
    analysis_version: Optional[str] = Field(None, max_length=32, description="åˆ†æç‰ˆæœ¬")
    status: Optional[str] = Field(None, description="åˆ†æçŠ¶æ€ï¼špending/success/failed")
    code_lines: Optional[int] = Field(None, description="ä»£ç è¡Œæ•°")
    code_content: Optional[str] = Field(None, description="ä»£ç å†…å®¹")
    file_analysis: Optional[str] = Field(None, description="æ–‡ä»¶åˆ†æç»“æœ")
    dependencies: Optional[str] = Field(None, description="ä¾èµ–æ¨¡å—åˆ—è¡¨")
    error_message: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")


class AnalysisItemCreate(BaseModel):
    """åˆ›å»ºåˆ†æé¡¹è®°å½•çš„è¯·æ±‚æ¨¡å‹"""

    file_analysis_id: int = Field(..., description="æ–‡ä»¶åˆ†æID")
    title: str = Field(..., min_length=1, max_length=512, description="æ ‡é¢˜")
    description: Optional[str] = Field(None, description="æè¿°")
    target_type: Optional[str] = Field(None, max_length=32, description="ç›®æ ‡ç±»å‹ï¼šfile/class/function")
    target_name: Optional[str] = Field(None, max_length=255, description="ç›®æ ‡åç§°ï¼ˆç±»å/å‡½æ•°åï¼‰")
    source: Optional[str] = Field(None, max_length=1024, description="æºç ä½ç½®")
    language: Optional[str] = Field(None, max_length=64, description="ç¼–ç¨‹è¯­è¨€")
    code: Optional[str] = Field(None, description="ä»£ç ç‰‡æ®µ")
    start_line: Optional[int] = Field(None, description="èµ·å§‹è¡Œå·")
    end_line: Optional[int] = Field(None, description="ç»“æŸè¡Œå·")


class AnalysisItemUpdate(BaseModel):
    """æ›´æ–°åˆ†æé¡¹è®°å½•çš„è¯·æ±‚æ¨¡å‹"""

    file_analysis_id: Optional[int] = Field(None, description="æ–‡ä»¶åˆ†æID")
    title: Optional[str] = Field(None, min_length=1, max_length=512, description="æ ‡é¢˜")
    description: Optional[str] = Field(None, description="æè¿°")
    target_type: Optional[str] = Field(None, max_length=32, description="ç›®æ ‡ç±»å‹ï¼šfile/class/function")
    target_name: Optional[str] = Field(None, max_length=255, description="ç›®æ ‡åç§°ï¼ˆç±»å/å‡½æ•°åï¼‰")
    source: Optional[str] = Field(None, max_length=1024, description="æºç ä½ç½®")
    language: Optional[str] = Field(None, max_length=64, description="ç¼–ç¨‹è¯­è¨€")
    code: Optional[str] = Field(None, description="ä»£ç ç‰‡æ®µ")
    start_line: Optional[int] = Field(None, description="èµ·å§‹è¡Œå·")
    end_line: Optional[int] = Field(None, description="ç»“æŸè¡Œå·")


class TaskReadmeCreate(BaseModel):
    """åˆ›å»ºä»»åŠ¡READMEçš„è¯·æ±‚æ¨¡å‹"""

    task_id: int = Field(..., description="ä»»åŠ¡ID")
    content: str = Field(..., min_length=1, description="readmeçš„å®Œæ•´å†…å®¹")


class TaskReadmeUpdate(BaseModel):
    """æ›´æ–°ä»»åŠ¡READMEçš„è¯·æ±‚æ¨¡å‹"""

    task_id: Optional[int] = Field(None, description="ä»»åŠ¡ID")
    content: Optional[str] = Field(None, min_length=1, description="readmeçš„å®Œæ•´å†…å®¹")


class PasswordVerifyRequest(BaseModel):
    """å¯†ç éªŒè¯è¯·æ±‚æ¨¡å‹"""

    password: str = Field(..., min_length=1, description="å¯†ç ")


# åˆ›å»ºè·¯ç”±å™¨
repository_router = APIRouter(prefix="/api/repository", tags=["ä»“åº“ç®¡ç†"])
analysis_router = APIRouter(prefix="/api/analysis", tags=["åˆ†æç®¡ç†"])
auth_router = APIRouter(prefix="/api/auth", tags=["è®¤è¯ç®¡ç†"])


@auth_router.post("/verify-password")
async def verify_password(request: PasswordVerifyRequest):
    """
    éªŒè¯å¯†ç 
    """
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–è®¾ç½®çš„å¯†ç 
        correct_password = os.getenv("PASSWORD", "123456")

        if request.password == correct_password:
            return JSONResponse(status_code=200, content={"success": True, "message": "å¯†ç éªŒè¯æˆåŠŸ"})
        else:
            return JSONResponse(status_code=200, content={"success": False, "message": "å¯†ç é”™è¯¯"})
    except Exception as e:
        logger.error(f"å¯†ç éªŒè¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return JSONResponse(status_code=500, content={"success": False, "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"})


@repository_router.get("/repositories/{repository_id}")
async def get_repository_by_id(
    repository_id: int,
    db: Session = Depends(get_db),
    include_tasks: bool = Query(False, description="æ˜¯å¦åŒ…å«åˆ†æä»»åŠ¡ä¿¡æ¯"),
):
    """
    æ ¹æ®ä»“åº“IDè·å–ä»“åº“è¯¦ç»†ä¿¡æ¯

    Args:
        repository_id: ä»“åº“ID
        db: æ•°æ®åº“ä¼šè¯
        include_tasks: æ˜¯å¦åŒ…å«åˆ†æä»»åŠ¡ä¿¡æ¯(é»˜è®¤Falseä»¥æå‡æ€§èƒ½)

    Returns:
        JSONå“åº”åŒ…å«ä»“åº“è¯¦ç»†ä¿¡æ¯
    """
    try:
        # è·å–ä»“åº“ä¿¡æ¯
        result = RepositoryService.get_repository_by_id(repository_id, db, include_tasks=include_tasks)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        if not result.get("repository"):
            return JSONResponse(status_code=404, content=result)

        # å¦‚æœæˆåŠŸè·å–åˆ°ä»“åº“ä¿¡æ¯ï¼Œå¤„ç†è·¯å¾„è½¬æ¢
        if result["status"] == "success" and result.get("repository"):
            repository = result["repository"]
            local_path = repository.get("local_path", "")

            # æ£€æŸ¥æ˜¯å¦ä¸ºç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœæ˜¯åˆ™è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if local_path and not os.path.isabs(local_path):
                # ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                # è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œç„¶åå‘ä¸Šä¸¤çº§å¾—åˆ°é¡¹ç›®æ ¹ç›®å½•
                current_file = os.path.abspath(__file__)  # backend/routers.py
                backend_dir = os.path.dirname(current_file)  # backend/
                project_root = os.path.dirname(backend_dir)  # Code-reader/

                # æ•°æ®åº“ä¸­å­˜å‚¨çš„è·¯å¾„é€šå¸¸æ˜¯ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„
                # ä¾‹å¦‚: ../data/repos/fcb4af8be6d3bc8f5da20e6c2e746b6b
                # è¿™ä¸ªè·¯å¾„æ˜¯ç›¸å¯¹äº backend/ ç›®å½•çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä» backend ç›®å½•å¼€å§‹è§£æ
                absolute_path = os.path.abspath(os.path.join(backend_dir, local_path))

                repository["absolute_local_path"] = absolute_path
                logger.info(f"è·¯å¾„è½¬æ¢: {local_path} -> {absolute_path}")
                logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
                logger.info(f"åç«¯ç›®å½•: {backend_dir}")
            else:
                repository["absolute_local_path"] = local_path

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–ä»“åº“ä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "repository_id": repository_id,
                "error": str(e),
            },
        )


@repository_router.get("/repositories")
async def get_repository_by_name_or_full_name(
    name: Optional[str] = Query(None, description="ä»“åº“åç§°ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰"),
    full_name: Optional[str] = Query(None, description="å®Œæ•´ä»“åº“åï¼ˆç²¾ç¡®åŒ¹é…ï¼‰"),
    db: Session = Depends(get_db),
):
    """
    æ ¹æ®ä»“åº“åç§°æˆ–å®Œæ•´ä»“åº“åç²¾ç¡®æŸ¥è¯¢ä»“åº“ä¿¡æ¯

    Args:
        name: ä»“åº“åç§°ï¼ˆç²¾ç¡®åŒ¹é…ï¼Œå¯é€‰ï¼‰
        full_name: å®Œæ•´ä»“åº“åï¼ˆç²¾ç¡®åŒ¹é…ï¼Œå¯é€‰ï¼‰
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«ä»“åº“ä¿¡æ¯

    Note:
        name å’Œ full_name è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªå‚æ•°
    """
    try:
        # éªŒè¯å‚æ•°
        if not name and not full_name:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "è¯·æä¾› name æˆ– full_name å‚æ•°è¿›è¡ŒæŸ¥è¯¢",
                },
            )

        # æ ¹æ®æä¾›çš„å‚æ•°è¿›è¡ŒæŸ¥è¯¢
        if name and full_name:
            # å¦‚æœåŒæ—¶æä¾›äº†ä¸¤ä¸ªå‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ full_name
            result = RepositoryService.get_repository_by_name_or_full_name(
                name=None, full_name=full_name, db=db, include_tasks=False
            )
            search_field = "full_name"
            search_value = full_name
        elif full_name:
            result = RepositoryService.get_repository_by_name_or_full_name(
                name=None, full_name=full_name, db=db, include_tasks=False
            )
            search_field = "full_name"
            search_value = full_name
        else:
            result = RepositoryService.get_repository_by_name_or_full_name(
                name=name, full_name=None, db=db, include_tasks=False
            )
            search_field = "name"
            search_value = name

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        if not result.get("repository"):
            return JSONResponse(status_code=404, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æŸ¥è¯¢ä»“åº“ä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "search_field": search_field if "search_field" in locals() else "unknown",
                "search_value": search_value if "search_value" in locals() else "unknown",
                "error": str(e),
            },
        )


@repository_router.post("/repositories")
async def create_repository(
    repository_data: RepositoryCreate,
    db: Session = Depends(get_db),
):
    """
    åˆ›å»ºæ–°ä»“åº“

    Args:
        repository_data: ä»“åº“åˆ›å»ºæ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ›å»ºçš„ä»“åº“ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = repository_data.model_dump()

        # åˆ›å»ºä»“åº“
        result = RepositoryService.create_repository(data_dict, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=201, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ›å»ºä»“åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.get("/repositories-list")
async def get_repositories_list(
    user_id: Optional[int] = Query(None, description="æŒ‰ç”¨æˆ·IDç­›é€‰"),
    status: Optional[int] = Query(None, description="æŒ‰çŠ¶æ€ç­›é€‰: 1=å­˜åœ¨ï¼Œ0=å·²åˆ é™¤"),
    order_by: str = Query(
        "created_at", description="æ’åºå­—æ®µ: id, user_id, name, full_name, status, created_at, updated_at"
    ),
    order_direction: str = Query("desc", description="æ’åºæ–¹å‘: asc, desc"),
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(10, ge=1, le=100, description="æ¯é¡µæ•°é‡ï¼Œ1-100"),
    db: Session = Depends(get_db),
):
    """
    è·å–ä»“åº“åˆ—è¡¨ï¼Œæ”¯æŒç­›é€‰ã€æ’åºå’Œåˆ†é¡µ

    Args:
        user_id: ç”¨æˆ·IDç­›é€‰ï¼ˆå¯é€‰ï¼‰
        status: çŠ¶æ€ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        order_by: æ’åºå­—æ®µ
        order_direction: æ’åºæ–¹å‘
        page: é¡µç 
        page_size: æ¯é¡µæ•°é‡
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«ä»“åº“åˆ—è¡¨å’Œåˆ†é¡µä¿¡æ¯
    """
    try:
        # è°ƒç”¨æœåŠ¡å±‚æ–¹æ³•
        result = RepositoryService.get_repositories_list(
            user_id=user_id,
            status=status,
            order_by=order_by,
            order_direction=order_direction,
            page=page,
            page_size=page_size,
            db=db,
        )

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–ä»“åº“åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.get("/analysis-tasks/{repository_id}")
async def get_analysis_tasks_by_repository(
    repository_id: int,
    db: Session = Depends(get_db),
    order_by: str = Query(
        "start_time",
        description="æ’åºå­—æ®µ: start_time, end_time, status, total_files, successful_files, failed_files, code_lines, module_count, id",
    ),
    order_direction: str = Query("asc", description="æ’åºæ–¹å‘: asc, desc"),
):
    """
    æ ¹æ®ä»“åº“IDè·å–åˆ†æä»»åŠ¡åˆ—è¡¨

    Args:
        repository_id: ä»“åº“ID
        db: æ•°æ®åº“ä¼šè¯
        order_by: æ’åºå­—æ®µ
        order_direction: æ’åºæ–¹å‘

    Returns:
        JSONå“åº”åŒ…å«åˆ†æä»»åŠ¡åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # è·å–åˆ†æä»»åŠ¡åˆ—è¡¨
        result = AnalysisTaskService.get_tasks_by_repository_id(repository_id, db, order_by, order_direction)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†æä»»åŠ¡
        if result["total_tasks"] == 0:
            return JSONResponse(status_code=404, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–åˆ†æä»»åŠ¡åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "repository_id": repository_id,
                "error": str(e),
            },
        )


@repository_router.post("/analysis-tasks")
async def create_analysis_task(
    task_data: AnalysisTaskCreate,
    db: Session = Depends(get_db),
):
    """
    åˆ›å»ºæ–°çš„åˆ†æä»»åŠ¡

    Args:
        task_data: åˆ†æä»»åŠ¡åˆ›å»ºæ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ›å»ºçš„åˆ†æä»»åŠ¡ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = task_data.model_dump()

        # åˆ›å»ºåˆ†æä»»åŠ¡
        result = AnalysisTaskService.create_analysis_task(data_dict, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=201, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ›å»ºåˆ†æä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.put("/analysis-tasks/{task_id}")
async def update_analysis_task(
    task_id: int,
    task_data: AnalysisTaskUpdate,
    db: Session = Depends(get_db),
):
    """
    æ›´æ–°åˆ†æä»»åŠ¡ä¿¡æ¯

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        task_data: åˆ†æä»»åŠ¡æ›´æ–°æ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ›´æ–°åçš„åˆ†æä»»åŠ¡ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸ï¼Œæ’é™¤Noneå€¼
        data_dict = task_data.model_dump(exclude_none=True)

        if not data_dict:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ",
                    "task_id": task_id,
                },
            )

        # æ›´æ–°åˆ†æä»»åŠ¡
        result = AnalysisTaskService.update_analysis_task(task_id, data_dict, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æ›´æ–°åˆ†æä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "task_id": task_id,
                "error": str(e),
            },
        )


@repository_router.delete("/analysis-tasks/{task_id}")
async def delete_analysis_task(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    åˆ é™¤åˆ†æä»»åŠ¡

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ é™¤ç»“æœ
    """
    try:
        # åˆ é™¤åˆ†æä»»åŠ¡
        result = AnalysisTaskService.delete_analysis_task(task_id, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ é™¤åˆ†æä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "task_id": task_id,
                "error": str(e),
            },
        )


@repository_router.get("/analysis-tasks/detail/{task_id}")
async def get_analysis_task_detail(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    è·å–æŒ‡å®šåˆ†æä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯(åŒ…å«æ•°æ®æ¨¡å‹åˆ†æè¿›åº¦)

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ†æä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        # æŸ¥è¯¢åˆ†æä»»åŠ¡
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {task_id} çš„åˆ†æä»»åŠ¡",
                },
            )

        # æŸ¥è¯¢æ•°æ®æ¨¡å‹åˆ†æè¿›åº¦
        file_analyses = db.query(FileAnalysis).filter(FileAnalysis.task_id == task_id).all()
        analysis_total = len(file_analyses)
        analysis_success = sum(1 for f in file_analyses if f.status == 'success')
        analysis_pending = sum(1 for f in file_analyses if f.status == 'pending')
        analysis_failed = sum(1 for f in file_analyses if f.status == 'failed')

        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        vectorize_progress = 0
        if task.total_files and task.total_files > 0:
            vectorize_progress = round((task.successful_files / task.total_files) * 100)

        analysis_progress = 0
        if analysis_total > 0:
            analysis_progress = round((analysis_success / analysis_total) * 100)

        # è¿”å›ä»»åŠ¡ä¿¡æ¯(åŒ…å«ä¸¤ä¸ªé˜¶æ®µçš„è¿›åº¦)
        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": "è·å–åˆ†æä»»åŠ¡ä¿¡æ¯æˆåŠŸ",
                "task": {
                    "id": task.id,
                    "status": task.status,
                    "current_file": task.current_file,
                    "start_time": task.start_time.isoformat() if task.start_time else None,
                    "end_time": task.end_time.isoformat() if task.end_time else None,
                    # å‘é‡åŒ–é˜¶æ®µè¿›åº¦
                    "total_files": task.total_files or 0,
                    "successful_files": task.successful_files or 0,
                    "failed_files": task.failed_files or 0,
                    "vectorize_progress": vectorize_progress,
                    # æ•°æ®æ¨¡å‹åˆ†æé˜¶æ®µè¿›åº¦
                    "analysis_total_files": analysis_total,
                    "analysis_success_files": analysis_success,
                    "analysis_pending_files": analysis_pending,
                    "analysis_failed_files": analysis_failed,
                    "analysis_progress": analysis_progress,
                    "task_index": task.task_index,
                    # å…³é”®æŒ‡æ ‡
                    "code_lines": task.code_lines or 0,
                    "module_count": task.module_count or 0,
                    # DeepWiki æ–‡æ¡£ç”Ÿæˆä»»åŠ¡ ID
                    "deepwiki_task_id": task.deepwiki_task_id,
                },
            },
        )

    except Exception as e:
        logger.error(f"è·å–åˆ†æä»»åŠ¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–åˆ†æä»»åŠ¡ä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.get("/analysis-tasks/{task_id}/can-start")
async def can_start_analysis_task(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    åˆ¤æ–­åˆ†æä»»åŠ¡æ˜¯å¦å¯ä»¥å¼€å¯

    åˆ¤æ–­æŒ‡å®šçš„ä»»åŠ¡IDæ˜¯å¦æ»¡è¶³å¼€å¯æ¡ä»¶ï¼š
    1. å½“å‰æ²¡æœ‰çŠ¶æ€ä¸º running çš„ä»»åŠ¡
    2. æŒ‡å®šçš„ task_id åœ¨çŠ¶æ€ä¸º pending çš„ä»»åŠ¡ä¸­æ˜¯ start_time æœ€æ—©çš„

    Args:
        task_id: è¦åˆ¤æ–­çš„ä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ¤æ–­ç»“æœï¼š
        - can_start: booleanï¼Œæ˜¯å¦å¯ä»¥å¼€å¯
        - reason: stringï¼Œåˆ¤æ–­åŸå› 
        - å…¶ä»–ç›¸å…³ä¿¡æ¯
    """
    try:
        # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å¯ä»¥å¼€å¯
        result = AnalysisTaskService.can_start_task(task_id, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å¯ä»¥å¼€å¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "task_id": task_id,
                "can_start": False,
                "error": str(e),
            },
        )


@repository_router.get("/analysis-tasks/queue/status")
async def get_queue_status(
    db: Session = Depends(get_db),
):
    """
    è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€

    Args:
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
    """
    try:
        # è·å–é˜Ÿåˆ—çŠ¶æ€
        result = AnalysisTaskService.get_queue_status(db)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–é˜Ÿåˆ—çŠ¶æ€æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.get("/files/{task_id}")
async def get_repository_files(
    task_id: int,
    db: Session = Depends(get_db),
    language: Optional[str] = Query(None, description="æŒ‰ç¼–ç¨‹è¯­è¨€è¿‡æ»¤"),
    analysis_version: Optional[str] = Query(None, description="æŒ‰åˆ†æç‰ˆæœ¬è¿‡æ»¤"),
    status: Optional[str] = Query(None, description="æŒ‰åˆ†æçŠ¶æ€è¿‡æ»¤: pending, success, failed"),
    include_code_content: bool = Query(False, description="æ˜¯å¦è¿”å›ä»£ç å†…å®¹"),
):
    """
    è·å–æŒ‡å®šä»»åŠ¡IDçš„ä»“åº“æ–‡ä»¶åˆ—è¡¨

    Args:
        task_id: ä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯
        language: ç¼–ç¨‹è¯­è¨€è¿‡æ»¤å™¨
        analysis_version: åˆ†æç‰ˆæœ¬è¿‡æ»¤å™¨
        status: çŠ¶æ€è¿‡æ»¤å™¨
        include_code_content: æ˜¯å¦è¿”å›ä»£ç å†…å®¹

    Returns:
        JSONå“åº”åŒ…å«æ–‡ä»¶åˆ—è¡¨
    """
    try:
        # è·å–æ–‡ä»¶åˆ—è¡¨
        result = FileAnalysisService.get_files_by_task_id(
            task_id,
            db,
            language=language,
            analysis_version=analysis_version,
            status=status,
            include_code_content=include_code_content,
        )

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶
        if result["total_files"] == 0:
            return JSONResponse(status_code=404, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": "è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯", "task_id": task_id, "error": str(e)},
        )


@repository_router.get("/file-analysis/{file_id}")
async def get_file_analysis_by_id(
    file_id: int,
    task_id: int = Query(..., description="ä»»åŠ¡ID"),
    db: Session = Depends(get_db),
):
    """
    æ ¹æ®æ–‡ä»¶åˆ†æIDå’Œä»»åŠ¡IDè·å–å•æ¡æ–‡ä»¶åˆ†æè®°å½•çš„å®Œæ•´å†…å®¹

    Args:
        file_id: æ–‡ä»¶åˆ†æè®°å½•ID
        task_id: ä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«å®Œæ•´çš„æ–‡ä»¶åˆ†æè®°å½•
    """
    try:
        # è·å–æ–‡ä»¶åˆ†æè®°å½•
        result = FileAnalysisService.get_file_analysis_by_id_and_task_id(file_id, task_id, db)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è®°å½•
        if not result.get("file_analysis"):
            return JSONResponse(status_code=404, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–æ–‡ä»¶åˆ†æè®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "file_id": file_id,
                "task_id": task_id,
                "error": str(e),
            },
        )


@repository_router.post("/file-analysis")
async def create_file_analysis(
    file_data: FileAnalysisCreate,
    db: Session = Depends(get_db),
):
    """
    åˆ›å»ºæ–°çš„æ–‡ä»¶åˆ†æè®°å½•

    Args:
        file_data: æ–‡ä»¶åˆ†æåˆ›å»ºæ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ›å»ºçš„æ–‡ä»¶åˆ†æè®°å½•ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = file_data.model_dump()

        # åˆ›å»ºæ–‡ä»¶åˆ†æè®°å½•
        result = FileAnalysisService.create_file_analysis(data_dict, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=201, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ›å»ºæ–‡ä»¶åˆ†æè®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.put("/file-analysis/{file_id}")
async def update_file_analysis(
    file_id: int,
    file_data: FileAnalysisUpdate,
    db: Session = Depends(get_db),
):
    """
    æ›´æ–°æ–‡ä»¶åˆ†æè®°å½•ä¿¡æ¯

    Args:
        file_id: æ–‡ä»¶åˆ†æè®°å½•ID
        file_data: æ–‡ä»¶åˆ†ææ›´æ–°æ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ›´æ–°åçš„æ–‡ä»¶åˆ†æè®°å½•ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸ï¼Œæ’é™¤Noneå€¼
        data_dict = file_data.model_dump(exclude_none=True)

        if not data_dict:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ",
                    "file_id": file_id,
                },
            )

        # æ›´æ–°æ–‡ä»¶åˆ†æè®°å½•
        result = FileAnalysisService.update_file_analysis(file_id, data_dict, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æ›´æ–°æ–‡ä»¶åˆ†æè®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "file_id": file_id,
                "error": str(e),
            },
        )


@repository_router.delete("/file-analysis/{file_id}")
async def delete_file_analysis(
    file_id: int,
    db: Session = Depends(get_db),
):
    """
    åˆ é™¤æ–‡ä»¶åˆ†æè®°å½•

    Args:
        file_id: æ–‡ä»¶åˆ†æè®°å½•ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ é™¤ç»“æœ
    """
    try:
        # åˆ é™¤æ–‡ä»¶åˆ†æè®°å½•
        result = FileAnalysisService.delete_file_analysis(file_id, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ é™¤æ–‡ä»¶åˆ†æè®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "file_id": file_id,
                "error": str(e),
            },
        )


@repository_router.get("/analysis-items/{file_analysis_id}")
async def get_file_analysis_items(
    file_analysis_id: int,
    db: Session = Depends(get_db),
    target_type: Optional[str] = Query(None, description="æŒ‰ç›®æ ‡ç±»å‹è¿‡æ»¤: file, class, function"),
    language: Optional[str] = Query(None, description="æŒ‰ç¼–ç¨‹è¯­è¨€è¿‡æ»¤"),
):
    """
    è·å–æŒ‡å®šæ–‡ä»¶åˆ†æIDçš„åˆ†æé¡¹è¯¦ç»†å†…å®¹

    Args:
        file_analysis_id: æ–‡ä»¶åˆ†æID
        db: æ•°æ®åº“ä¼šè¯
        target_type: ç›®æ ‡ç±»å‹è¿‡æ»¤å™¨ (file/class/function)
        language: ç¼–ç¨‹è¯­è¨€è¿‡æ»¤å™¨

    Returns:
        JSONå“åº”åŒ…å«åˆ†æé¡¹åˆ—è¡¨ï¼ŒæŒ‰start_lineå‡åºæ’åº
    """
    try:
        # è·å–åˆ†æé¡¹åˆ—è¡¨
        result = AnalysisItemService.get_analysis_items_by_file_id(
            file_analysis_id, db, target_type=target_type, language=language
        )

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        # å³ä½¿æ²¡æœ‰åˆ†æé¡¹ä¹Ÿè¿”å›200ï¼Œå› ä¸ºè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼ˆæ–‡ä»¶å¯èƒ½è¿˜åœ¨åˆ†æä¸­æˆ–ç¡®å®æ²¡æœ‰å¯åˆ†æçš„å†…å®¹ï¼‰
        # 404åº”è¯¥åªç”¨äºfile_analysis_idæœ¬èº«ä¸å­˜åœ¨çš„æƒ…å†µ
        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–åˆ†æé¡¹åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "file_analysis_id": file_analysis_id,
                "error": str(e),
            },
        )


@repository_router.post("/analysis-items")
async def create_analysis_item(
    item_data: AnalysisItemCreate,
    db: Session = Depends(get_db),
):
    """
    åˆ›å»ºæ–°çš„åˆ†æé¡¹è®°å½•

    Args:
        item_data: åˆ†æé¡¹åˆ›å»ºæ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ›å»ºçš„åˆ†æé¡¹è®°å½•ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = item_data.model_dump()

        # åˆ›å»ºåˆ†æé¡¹è®°å½•
        result = AnalysisItemService.create_analysis_item(data_dict, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=201, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ›å»ºåˆ†æé¡¹è®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.put("/analysis-items/{item_id}")
async def update_analysis_item(
    item_id: int,
    item_data: AnalysisItemUpdate,
    db: Session = Depends(get_db),
):
    """
    æ›´æ–°åˆ†æé¡¹è®°å½•ä¿¡æ¯

    Args:
        item_id: åˆ†æé¡¹è®°å½•ID
        item_data: åˆ†æé¡¹æ›´æ–°æ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ›´æ–°åçš„åˆ†æé¡¹è®°å½•ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸ï¼Œæ’é™¤Noneå€¼
        data_dict = item_data.model_dump(exclude_none=True)

        if not data_dict:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ",
                    "item_id": item_id,
                },
            )

        # æ›´æ–°åˆ†æé¡¹è®°å½•
        result = AnalysisItemService.update_analysis_item(item_id, data_dict, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æ›´æ–°åˆ†æé¡¹è®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "item_id": item_id,
                "error": str(e),
            },
        )


@repository_router.delete("/analysis-items/{item_id}")
async def delete_analysis_item(
    item_id: int,
    db: Session = Depends(get_db),
):
    """
    åˆ é™¤åˆ†æé¡¹è®°å½•

    Args:
        item_id: åˆ†æé¡¹è®°å½•ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ é™¤ç»“æœ
    """
    try:
        # åˆ é™¤åˆ†æé¡¹è®°å½•
        result = AnalysisItemService.delete_analysis_item(item_id, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ é™¤åˆ†æé¡¹è®°å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "item_id": item_id,
                "error": str(e),
            },
        )


@repository_router.post("/upload")
async def upload_repository(
    files: List[UploadFile] = File(...),
    repository_name: str = Form(...),
    background_tasks: BackgroundTasks = None,
    db: Session = Depends(get_db),
):
    """
    ä¸Šä¼ å®Œæ•´çš„ä»“åº“æ–‡ä»¶å¤¹

    æ¥æ”¶å‰ç«¯ä¸Šä¼ çš„æ•´ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹ï¼Œä¿æŒå®Œæ•´çš„ç›®å½•ç»“æ„ï¼Œ
    å¹¶æä¾›è¯¦ç»†çš„æ–‡ä»¶å¤¹ç»“æ„åˆ†æå’Œç»Ÿè®¡ä¿¡æ¯ã€‚
    ä¸Šä¼ æˆåŠŸåä¼šè‡ªåŠ¨åˆ›å»ºåˆ†æä»»åŠ¡å¹¶è§¦å‘åˆ†ææµç¨‹ã€‚

    Args:
        files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆåŒ…å«å®Œæ•´æ–‡ä»¶å¤¹ç»“æ„ï¼‰
        repository_name: ä»“åº“åç§°
        background_tasks: åå°ä»»åŠ¡
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«ï¼š
        - ä¸Šä¼ ç»“æœå’Œä»“åº“ä¿¡æ¯
        - æ–‡ä»¶å¤¹ç»“æ„åˆ†æ
        - æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        - é¡¹ç›®ç‰¹å¾è¯†åˆ«
        - åˆ†æä»»åŠ¡ID
    """
    try:
        # è°ƒç”¨ä¸Šä¼ æœåŠ¡
        result = await UploadService.upload_repository_files(files, repository_name, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        # å¦‚æœä¸Šä¼ æˆåŠŸä¸”åˆ›å»ºäº†ä»»åŠ¡ï¼Œè‡ªåŠ¨è§¦å‘åˆ†æ
        task_id = result.get("task_id")
        repository_id = result.get("repository_id")
        local_path = result.get("local_path")

        if task_id and repository_id and local_path and background_tasks:
            # è·å–ä»“åº“ä¿¡æ¯
            repository = db.query(Repository).filter(Repository.id == repository_id).first()
            if repository:
                repo_info = {
                    "full_name": repository.full_name or repository.name,
                    "name": repository.name,
                    "local_path": repository.local_path,
                }

                # åœ¨åå°è‡ªåŠ¨è§¦å‘åˆ†ææµç¨‹
                async def run_analysis_pipeline():
                    """åå°è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
                    import sys
                    from pathlib import Path

                    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
                    project_root = Path(__file__).parent.parent
                    if str(project_root) not in sys.path:
                        sys.path.insert(0, str(project_root))

                    try:
                        from src.flows.web_flow import create_knowledge_base as create_kb_flow
                        from src.flows.web_flow import analyze_data_model as analyze_dm_flow

                        # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
                        from database import SessionLocal
                        db_session = SessionLocal()

                        try:
                            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
                            task = db_session.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                            if task:
                                task.status = "running"
                                db_session.commit()

                            # æ­¥éª¤1: åˆ›å»ºçŸ¥è¯†åº“
                            logger.info(f"[ä»»åŠ¡ {task_id}] å¼€å§‹åˆ›å»ºçŸ¥è¯†åº“...")
                            kb_result = await create_kb_flow(
                                task_id=task_id,
                                local_path=local_path,
                                repo_info=repo_info
                            )

                            if kb_result.get("status") != "knowledge_base_ready":
                                logger.error(f"[ä»»åŠ¡ {task_id}] çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {kb_result}")
                                task = db_session.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                                if task:
                                    task.status = "failed"
                                    db_session.commit()
                                return

                            logger.info(f"[ä»»åŠ¡ {task_id}] çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ")

                            # è·å–å‘é‡ç´¢å¼•åç§°
                            vectorstore_index = kb_result.get("vectorstore_index")
                            if not vectorstore_index:
                                logger.error(f"[ä»»åŠ¡ {task_id}] çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸä½†æœªè¿”å›å‘é‡ç´¢å¼•")
                                task = db_session.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                                if task:
                                    task.status = "failed"
                                    db_session.commit()
                                return

                            # æ­¥éª¤2: åˆ†ææ•°æ®æ¨¡å‹
                            logger.info(f"[ä»»åŠ¡ {task_id}] å¼€å§‹åˆ†ææ•°æ®æ¨¡å‹...")
                            dm_result = await analyze_dm_flow(
                                task_id=task_id,
                                vectorstore_index=vectorstore_index
                            )

                            if dm_result.get("status") == "completed":
                                logger.info(f"[ä»»åŠ¡ {task_id}] æ•°æ®æ¨¡å‹åˆ†ææˆåŠŸ")
                            else:
                                logger.error(f"[ä»»åŠ¡ {task_id}] æ•°æ®æ¨¡å‹åˆ†æå¤±è´¥: {dm_result}")

                        finally:
                            db_session.close()

                    except Exception as e:
                        logger.error(f"[ä»»åŠ¡ {task_id}] åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
                        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                        from database import SessionLocal
                        db_session = SessionLocal()
                        try:
                            task = db_session.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                            if task:
                                task.status = "failed"
                                db_session.commit()
                        finally:
                            db_session.close()

                # æ·»åŠ åå°ä»»åŠ¡
                background_tasks.add_task(run_analysis_pipeline)
                logger.info(f"âœ… å·²æ·»åŠ åå°åˆ†æä»»åŠ¡: ä»»åŠ¡ID={task_id}, ä»“åº“ID={repository_id}")

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "ä¸Šä¼ ä»“åº“æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "repository_name": repository_name,
                "error": str(e),
            },
        )


@analysis_router.post("/repository/{repository_id}/reanalyze")
async def reanalyze_repository(
    repository_id: int,
    db: Session = Depends(get_db),
):
    """
    é‡æ–°åˆ†æå·²æœ‰ä»“åº“ï¼ˆä½¿ç”¨ Celery å¼‚æ­¥ä»»åŠ¡ï¼‰

    ä¸ºå·²ä¸Šä¼ çš„ä»“åº“åˆ›å»ºæ–°çš„åˆ†æä»»åŠ¡å¹¶è‡ªåŠ¨å¼€å§‹åˆ†ææµç¨‹

    Args:
        repository_id: ä»“åº“ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ–°åˆ›å»ºçš„ä»»åŠ¡ä¿¡æ¯
    """
    try:
        # éªŒè¯ä»“åº“æ˜¯å¦å­˜åœ¨
        repository = db.query(Repository).filter(Repository.id == repository_id).first()
        if not repository:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {repository_id} çš„ä»“åº“",
                    "repository_id": repository_id,
                },
            )

        # æ£€æŸ¥ä»“åº“è·¯å¾„æ˜¯å¦å­˜åœ¨
        repo_path = os.path.join(os.getcwd(), repository.local_path)
        if not os.path.exists(repo_path):
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": f"ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {repo_path}",
                    "repository_id": repository_id,
                },
            )

        # ========== æ£€æŸ¥æ˜¯å¦æœ‰å¯æ¢å¤çš„å¤±è´¥ä»»åŠ¡ ==========
        failed_task = db.query(AnalysisTask).filter(
            AnalysisTask.repository_id == repository_id,
            AnalysisTask.status == 'failed'
        ).order_by(AnalysisTask.id.desc()).first()

        # å¦‚æœæœ‰å¤±è´¥ä»»åŠ¡ä¸”å‘é‡åŒ–å·²å®Œæˆï¼ˆæœ‰ task_indexï¼‰ï¼Œæ¢å¤è¯¥ä»»åŠ¡
        # ä¸ç®¡ successful_files æ˜¯å¦ > 0ï¼Œåªè¦å‘é‡åŒ–å®Œæˆå°±å¯ä»¥æ¢å¤
        if failed_task and failed_task.task_index:
            logger.info(f"ğŸ”„ å‘ç°å¯æ¢å¤çš„å¤±è´¥ä»»åŠ¡ {failed_task.id}ï¼Œå·²å®Œæˆ {failed_task.successful_files}/{failed_task.total_files} ä¸ªæ–‡ä»¶")

            # åœæ­¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            running_tasks = db.query(AnalysisTask).filter(
                AnalysisTask.repository_id == repository_id,
                AnalysisTask.status.in_(['running', 'pending'])
            ).all()

            if running_tasks:
                from tasks import celery_app

                for old_task in running_tasks:
                    logger.info(f"âš ï¸ å‘ç°ä»“åº“ {repository_id} çš„æ—§ä»»åŠ¡ {old_task.id}ï¼ˆçŠ¶æ€: {old_task.status}ï¼‰ï¼Œå‡†å¤‡åœæ­¢")

                    # å°è¯•æ‰¾åˆ°å¹¶æ’¤é”€å¯¹åº”çš„ Celery ä»»åŠ¡
                    try:
                        inspect = celery_app.control.inspect()
                        active_tasks = inspect.active()

                        if active_tasks:
                            for worker, tasks in active_tasks.items():
                                for task in tasks:
                                    if task['name'] == 'tasks.run_analysis_task':
                                        task_args = task.get('args', [])
                                        if task_args and len(task_args) > 0 and task_args[0] == old_task.id:
                                            celery_task_id = task['id']
                                            celery_app.control.revoke(celery_task_id, terminate=True, signal='SIGKILL')
                                            logger.info(f"âœ… å·²æ’¤é”€ Celery ä»»åŠ¡ {celery_task_id[:8]}... (å¯¹åº”ä»»åŠ¡ {old_task.id})")
                    except Exception as e:
                        logger.warning(f"æ’¤é”€ Celery ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")

                    old_task.status = 'cancelled'
                    logger.info(f"âœ… å·²å°†ä»»åŠ¡ {old_task.id} çŠ¶æ€æ›´æ–°ä¸º cancelled")

                db.commit()
                logger.info(f"âœ… å·²åœæ­¢ä»“åº“ {repository_id} çš„ {len(running_tasks)} ä¸ªæ—§ä»»åŠ¡")

            # æ¢å¤å¤±è´¥ä»»åŠ¡
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„æ–‡ä»¶
            remaining_files = failed_task.total_files - failed_task.successful_files

            if remaining_files > 0:
                # è¿˜æœ‰æ–‡ä»¶æœªå®Œæˆï¼Œé‡æ–°æäº¤ä»»åŠ¡
                failed_task.status = 'pending'
                failed_task.end_time = None
                db.commit()

                logger.info(f"âœ… æ¢å¤ä»»åŠ¡ {failed_task.id}ï¼Œå°†ç»§ç»­åˆ†æå‰©ä½™çš„ {remaining_files} ä¸ªæ–‡ä»¶")

                # æäº¤åˆ° Celery
                from tasks import run_analysis_task
                run_analysis_task.delay(failed_task.id, repository.local_path)

                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": f"å·²æ¢å¤ä»»åŠ¡ {failed_task.id}ï¼Œç»§ç»­åˆ†æå‰©ä½™çš„ {remaining_files} ä¸ªæ–‡ä»¶",
                        "task": {
                            "id": failed_task.id,
                            "repository_id": repository_id,
                            "status": failed_task.status,
                            "total_files": failed_task.total_files,
                            "successful_files": failed_task.successful_files,
                            "failed_files": failed_task.failed_files,
                        },
                    },
                )
            else:
                # æ‰€æœ‰æ–‡ä»¶éƒ½å·²å®Œæˆï¼Œç›´æ¥æ ‡è®°ä¸ºå®Œæˆ
                failed_task.status = 'completed'
                failed_task.end_time = datetime.now()
                db.commit()

                logger.info(f"âœ… ä»»åŠ¡ {failed_task.id} æ‰€æœ‰æ–‡ä»¶å·²å®Œæˆï¼Œæ ‡è®°ä¸ºå®Œæˆ")

                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": f"ä»»åŠ¡ {failed_task.id} å·²å®Œæˆ",
                        "task": {
                            "id": failed_task.id,
                            "repository_id": repository_id,
                            "status": failed_task.status,
                            "total_files": failed_task.total_files,
                            "successful_files": failed_task.successful_files,
                            "failed_files": failed_task.failed_files,
                        },
                    },
                )

        # ========== åœæ­¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ ==========
        running_tasks = db.query(AnalysisTask).filter(
            AnalysisTask.repository_id == repository_id,
            AnalysisTask.status.in_(['running', 'pending'])
        ).all()

        if running_tasks:
            from tasks import celery_app

            for old_task in running_tasks:
                logger.info(f"âš ï¸ å‘ç°ä»“åº“ {repository_id} çš„æ—§ä»»åŠ¡ {old_task.id}ï¼ˆçŠ¶æ€: {old_task.status}ï¼‰ï¼Œå‡†å¤‡åœæ­¢")

                # å°è¯•æ‰¾åˆ°å¹¶æ’¤é”€å¯¹åº”çš„ Celery ä»»åŠ¡
                try:
                    inspect = celery_app.control.inspect()
                    active_tasks = inspect.active()

                    if active_tasks:
                        for worker, tasks in active_tasks.items():
                            for task in tasks:
                                if task['name'] == 'tasks.run_analysis_task':
                                    task_args = task.get('args', [])
                                    if task_args and len(task_args) > 0 and task_args[0] == old_task.id:
                                        celery_task_id = task['id']
                                        celery_app.control.revoke(celery_task_id, terminate=True, signal='SIGKILL')
                                        logger.info(f"âœ… å·²æ’¤é”€ Celery ä»»åŠ¡ {celery_task_id[:8]}... (å¯¹åº”ä»»åŠ¡ {old_task.id})")
                except Exception as e:
                    logger.warning(f"æ’¤é”€ Celery ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")

                old_task.status = 'cancelled'
                logger.info(f"âœ… å·²å°†ä»»åŠ¡ {old_task.id} çŠ¶æ€æ›´æ–°ä¸º cancelled")

            db.commit()
            logger.info(f"âœ… å·²åœæ­¢ä»“åº“ {repository_id} çš„ {len(running_tasks)} ä¸ªæ—§ä»»åŠ¡")

        # åˆ›å»ºæ–°çš„åˆ†æä»»åŠ¡
        new_task = AnalysisTask(
            repository_id=repository_id,
            status="pending",
            total_files=0,
            successful_files=0,
            failed_files=0,
            code_lines=0,
            module_count=0,
        )
        db.add(new_task)
        db.commit()
        db.refresh(new_task)

        logger.info(f"ä¸ºä»“åº“ {repository_id} åˆ›å»ºäº†æ–°çš„åˆ†æä»»åŠ¡ {new_task.id}")

        # å‡†å¤‡ä»“åº“ä¿¡æ¯
        repo_info = {
            "full_name": repository.full_name or repository.name,
            "name": repository.name,
            "local_path": repository.local_path,
        }

        # ä½¿ç”¨ Celery å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œåˆ†ææµç¨‹
        from tasks import run_analysis_task

        celery_task = run_analysis_task.delay(new_task.id, repo_info)

        logger.info(f"å·²æäº¤ä»»åŠ¡ {new_task.id} åˆ° Celery é˜Ÿåˆ— (Celeryä»»åŠ¡ID: {celery_task.id})")

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": "é‡æ–°åˆ†æä»»åŠ¡å·²åˆ›å»ºå¹¶æäº¤åˆ°åå°é˜Ÿåˆ—",
                "repository_id": repository_id,
                "task_id": new_task.id,
                "repository_name": repository.name,
                "celery_task_id": celery_task.id,
            },
        )

    except Exception as e:
        logger.error(f"é‡æ–°åˆ†æä»“åº“å¤±è´¥: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "é‡æ–°åˆ†æä»“åº“æ—¶å‘ç”Ÿé”™è¯¯",
                "repository_id": repository_id,
                "error": str(e),
            },
        )


@analysis_router.post("/{task_id}/create-knowledge-base")
async def create_knowledge_base(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    ä¸ºæŒ‡å®šä»»åŠ¡åˆ›å»ºçŸ¥è¯†åº“

    è§¦å‘çŸ¥è¯†åº“åˆ›å»ºflowï¼ŒåŒ…å«å‘é‡åŒ–å’Œæ•°æ®åº“æ›´æ–°

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«çŸ¥è¯†åº“åˆ›å»ºçŠ¶æ€å’Œè¿›åº¦ä¿¡æ¯
    """
    try:
        # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {task_id} çš„åˆ†æä»»åŠ¡",
                    "task_id": task_id,
                },
            )

        # è·å–ä»“åº“ä¿¡æ¯
        repository = db.query(Repository).filter(Repository.id == task.repository_id).first()
        if not repository:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°ä»“åº“IDä¸º {task.repository_id} çš„ä»“åº“",
                    "task_id": task_id,
                },
            )

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if task.status not in ["pending", "running"]:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": f"ä»»åŠ¡çŠ¶æ€ä¸º {task.status}ï¼Œæ— æ³•åˆ›å»ºçŸ¥è¯†åº“",
                    "task_id": task_id,
                },
            )

        # å‡†å¤‡ä»“åº“ä¿¡æ¯
        repo_info = {
            "full_name": repository.full_name or repository.name,
            "name": repository.name,
            "local_path": repository.local_path,
        }

        # å¯åŠ¨çŸ¥è¯†åº“åˆ›å»ºflowï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
        import asyncio
        import sys
        from pathlib import Path

        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))

        try:
            from src.flows.web_flow import create_knowledge_base as create_kb_flow
        except ImportError as e:
            logger.error(f"å¯¼å…¥çŸ¥è¯†åº“åˆ›å»ºflowå¤±è´¥: {str(e)}")
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"å¯¼å…¥çŸ¥è¯†åº“åˆ›å»ºflowå¤±è´¥: {str(e)}",
                    "task_id": task_id,
                },
            )

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task.status = "running"
        db.commit()

        # åŒæ­¥æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºflowï¼Œç­‰å¾…å®Œæˆåè¿”å›ç»“æœ
        try:
            logger.info(f"å¼€å§‹æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºflowï¼Œä»»åŠ¡ID: {task_id}")
            result = await create_kb_flow(task_id=task_id, local_path=repository.local_path, repo_info=repo_info)

            # æ£€æŸ¥flowæ‰§è¡Œç»“æœ
            if result.get("status") == "knowledge_base_ready" and result.get("vectorstore_index"):
                logger.info(f"çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸï¼Œç´¢å¼•: {result.get('vectorstore_index')}")
                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": "çŸ¥è¯†åº“åˆ›å»ºå®Œæˆ",
                        "task_id": task_id,
                        "task_status": "running",  # ä¿æŒrunningçŠ¶æ€ï¼Œç­‰å¾…åç»­æ­¥éª¤
                        "vectorstore_index": result.get("vectorstore_index"),
                    },
                )
            else:
                logger.error(f"çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {result}")
                # å›æ»šä»»åŠ¡çŠ¶æ€
                task.status = "failed"
                db.commit()
                return JSONResponse(
                    status_code=500,
                    content={
                        "status": "error",
                        "message": f"çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                        "task_id": task_id,
                    },
                )

        except Exception as e:
            logger.error(f"æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºflowå¤±è´¥: {str(e)}")
            # å›æ»šä»»åŠ¡çŠ¶æ€
            task.status = "failed"
            db.commit()
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºflowå¤±è´¥: {str(e)}",
                    "task_id": task_id,
                },
            )

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "å¯åŠ¨çŸ¥è¯†åº“åˆ›å»ºæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "task_id": task_id,
                "error": str(e),
            },
        )


@analysis_router.post("/{task_id}/analyze-data-model")
async def analyze_data_model(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    ä¸ºæŒ‡å®šä»»åŠ¡æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹

    è§¦å‘åˆ†ææ•°æ®æ¨¡å‹flowï¼ŒåŒ…å«ä»£ç åˆ†æå’Œæ•°æ®åº“æ›´æ–°

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ†ææ•°æ®æ¨¡å‹çŠ¶æ€å’Œè¿›åº¦ä¿¡æ¯
    """
    try:
        # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {task_id} çš„åˆ†æä»»åŠ¡",
                    "task_id": task_id,
                },
            )

        # è·å–ä»“åº“ä¿¡æ¯
        repository = db.query(Repository).filter(Repository.id == task.repository_id).first()
        if not repository:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°ä»“åº“IDä¸º {task.repository_id} çš„ä»“åº“",
                    "task_id": task_id,
                },
            )

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if task.status not in ["pending", "running", "completed"]:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": f"ä»»åŠ¡çŠ¶æ€ä¸º {task.status}ï¼Œæ— æ³•æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹",
                    "task_id": task_id,
                },
            )

        # æ£€æŸ¥æ˜¯å¦æœ‰çŸ¥è¯†åº“ç´¢å¼•
        if not task.task_index:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "ä»»åŠ¡ç¼ºå°‘çŸ¥è¯†åº“ç´¢å¼•ï¼Œè¯·å…ˆå®ŒæˆçŸ¥è¯†åº“åˆ›å»º",
                    "task_id": task_id,
                },
            )

        # å¯åŠ¨åˆ†ææ•°æ®æ¨¡å‹flowï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
        import sys
        from pathlib import Path

        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))

        try:
            from src.flows.web_flow import analyze_data_model as analyze_dm_flow
        except ImportError as e:
            logger.error(f"å¯¼å…¥åˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}")
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"å¯¼å…¥åˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}",
                    "task_id": task_id,
                },
            )

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task.status = "running"
        db.commit()

        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹flowï¼Œä»»åŠ¡ID: {task_id}")
            result = await analyze_dm_flow(task_id=task_id, vectorstore_index=task.task_index)

            # æ£€æŸ¥flowæ‰§è¡Œç»“æœ
            if result.get("status") == "analysis_completed":
                analysis_items_count = result.get("analysis_items_count", 0)
                total_files = result.get("total_files", 0)
                successful_files = result.get("successful_files", 0)
                failed_files = result.get("failed_files", 0)
                success_rate = result.get("success_rate", "0%")

                logger.info(
                    f"åˆ†ææ•°æ®æ¨¡å‹å®Œæˆ: æ€»æ–‡ä»¶ {total_files}, æˆåŠŸ {successful_files}, å¤±è´¥ {failed_files}, åˆ†æé¡¹ {analysis_items_count}"
                )

                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": result.get("message", "åˆ†ææ•°æ®æ¨¡å‹å®Œæˆ"),
                        "task_id": task_id,
                        "task_status": "running",  # ä¿æŒrunningçŠ¶æ€ï¼Œç­‰å¾…åç»­æ­¥éª¤
                        "analysis_items_count": analysis_items_count,
                        "total_files": total_files,
                        "successful_files": successful_files,
                        "failed_files": failed_files,
                        "success_rate": success_rate,
                        "analysis_results": result.get("analysis_results", []),
                    },
                )
            else:
                logger.error(f"åˆ†ææ•°æ®æ¨¡å‹å¤±è´¥: {result}")
                # å›æ»šä»»åŠ¡çŠ¶æ€
                task.status = "failed"
                db.commit()
                return JSONResponse(
                    status_code=500,
                    content={
                        "status": "error",
                        "message": f"åˆ†ææ•°æ®æ¨¡å‹å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                        "task_id": task_id,
                        "error_details": result.get("message", ""),
                    },
                )

        except Exception as e:
            logger.error(f"æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}")
            # å›æ»šä»»åŠ¡çŠ¶æ€
            task.status = "failed"
            db.commit()
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}",
                    "task_id": task_id,
                },
            )

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "å¯åŠ¨åˆ†ææ•°æ®æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "task_id": task_id,
                "error": str(e),
            },
        )


@analysis_router.post("/file/{file_id}/analyze-data-model")
async def analyze_single_file_data_model(
    file_id: int,
    task_index: str = Query(..., description="ä»»åŠ¡ç´¢å¼•"),
    task_id: Optional[int] = Query(None, description="ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»æ–‡ä»¶åˆ†æè®°å½•ä¸­è·å–ï¼‰"),
    db: Session = Depends(get_db),
):
    """
    ä¸ºæŒ‡å®šæ–‡ä»¶æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹

    è§¦å‘å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹flowï¼ŒåŒ…å«ä»£ç åˆ†æå’Œæ•°æ®åº“æ›´æ–°

    Args:
        file_id: æ–‡ä»¶åˆ†æID
        task_index: ä»»åŠ¡ç´¢å¼•ï¼ˆçŸ¥è¯†åº“ç´¢å¼•ï¼‰
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ†ææ•°æ®æ¨¡å‹çŠ¶æ€å’Œè¿›åº¦ä¿¡æ¯
    """
    try:
        # éªŒè¯æ–‡ä»¶åˆ†æè®°å½•æ˜¯å¦å­˜åœ¨
        # FileAnalysiså·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥äº†ï¼Œä¸éœ€è¦é‡å¤å¯¼å…¥

        file_analysis = db.query(FileAnalysis).filter(FileAnalysis.id == file_id).first()
        if not file_analysis:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {file_id} çš„æ–‡ä»¶åˆ†æè®°å½•",
                    "file_id": file_id,
                },
            )

        # è·å–å…³è”çš„ä»»åŠ¡ä¿¡æ¯
        task = db.query(AnalysisTask).filter(AnalysisTask.id == file_analysis.task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°ä»»åŠ¡IDä¸º {file_analysis.task_id} çš„åˆ†æä»»åŠ¡",
                    "file_id": file_id,
                },
            )

        # è·å–ä»“åº“ä¿¡æ¯
        repository = db.query(Repository).filter(Repository.id == task.repository_id).first()
        if not repository:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°ä»“åº“IDä¸º {task.repository_id} çš„ä»“åº“",
                    "file_id": file_id,
                },
            )

        # æ£€æŸ¥æ–‡ä»¶åˆ†æçŠ¶æ€
        if file_analysis.status == "failed":
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": f"æ–‡ä»¶åˆ†æçŠ¶æ€ä¸º {file_analysis.status}ï¼Œæ— æ³•æ‰§è¡Œåˆ†ææ•°æ®æ¨¡å‹",
                    "file_id": file_id,
                },
            )

        # å¯åŠ¨å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹flowï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
        import sys
        from pathlib import Path

        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))

        try:
            from src.flows.web_flow import analyze_single_file_data_model as analyze_single_file_flow
        except ImportError as e:
            logger.error(f"å¯¼å…¥å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}")
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"å¯¼å…¥å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹flowå¤±è´¥: {str(e)}",
                    "file_id": file_id,
                },
            )

        # ä½¿ç”¨ä¼ é€’çš„task_idæˆ–ä»æ•°æ®åº“è·å–çš„task_id
        actual_task_id = task_id if task_id is not None else task.id

        # ä½¿ç”¨Celeryå¼‚æ­¥ä»»åŠ¡å¤„ç†åˆ†æ
        celery_task = analyze_single_file_task.delay(
            task_id=actual_task_id,
            file_id=file_id,
            vectorstore_index=task_index
        )

        # ç«‹å³è¿”å›,ä¸ç­‰å¾…åˆ†æå®Œæˆ
        logger.info(f"å·²æäº¤æ–‡ä»¶ {file_id} åˆ°Celeryä»»åŠ¡é˜Ÿåˆ— (Celeryä»»åŠ¡ID: {celery_task.id})")
        return JSONResponse(
            status_code=202,  # 202 Accepted - è¯·æ±‚å·²æ¥å—,æ­£åœ¨å¤„ç†
            content={
                "status": "accepted",
                "message": "å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹å·²æäº¤åˆ°ä»»åŠ¡é˜Ÿåˆ—,æ­£åœ¨åå°æ‰§è¡Œ",
                "file_id": file_id,
                "file_path": file_analysis.file_path,
                "celery_task_id": celery_task.id,
            },
        )

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "å¯åŠ¨å•æ–‡ä»¶åˆ†ææ•°æ®æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "file_id": file_id,
                "error": str(e),
            },
        )


@repository_router.put("/repositories/{repository_id}")
async def update_repository(
    repository_id: int,
    repository_data: RepositoryUpdate,
    db: Session = Depends(get_db),
):
    """
    æ›´æ–°ä»“åº“ä¿¡æ¯

    Args:
        repository_id: ä»“åº“ID
        repository_data: ä»“åº“æ›´æ–°æ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ›´æ–°åçš„ä»“åº“ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸ï¼Œæ’é™¤Noneå€¼
        data_dict = repository_data.model_dump(exclude_none=True)

        if not data_dict:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ",
                    "repository_id": repository_id,
                },
            )

        # æ›´æ–°ä»“åº“
        result = RepositoryService.update_repository(repository_id, data_dict, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æ›´æ–°ä»“åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "repository_id": repository_id,
                "error": str(e),
            },
        )


@repository_router.delete("/repositories/{repository_id}")
async def delete_repository(
    repository_id: int,
    db: Session = Depends(get_db),
    soft_delete: bool = Query(True, description="æ˜¯å¦è½¯åˆ é™¤ï¼ˆTrue=è®¾ç½®statusä¸º0ï¼ŒFalse=ç‰©ç†åˆ é™¤ï¼‰"),
):
    """
    åˆ é™¤ä»“åº“ï¼ˆæ”¯æŒè½¯åˆ é™¤å’Œç¡¬åˆ é™¤ï¼‰

    Args:
        repository_id: ä»“åº“ID
        db: æ•°æ®åº“ä¼šè¯
        soft_delete: æ˜¯å¦è½¯åˆ é™¤

    Returns:
        JSONå“åº”åŒ…å«åˆ é™¤ç»“æœ
    """
    try:
        # åˆ é™¤ä»“åº“
        result = RepositoryService.delete_repository(repository_id, db, soft_delete=soft_delete)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ é™¤ä»“åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "repository_id": repository_id,
                "error": str(e),
            },
        )


# Task README ç›¸å…³è·¯ç”±
@repository_router.post("/task-readmes")
async def create_task_readme(
    readme_data: TaskReadmeCreate,
    db: Session = Depends(get_db),
):
    """
    åˆ›å»ºä»»åŠ¡README

    Args:
        readme_data: READMEåˆ›å»ºæ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ›å»ºçš„READMEä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = readme_data.model_dump()

        # åˆ›å»ºREADME
        result = TaskReadmeService.create_task_readme(data_dict, db)

        if result["status"] == "error":
            return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=201, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ›å»ºREADMEæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "error": str(e),
            },
        )


@repository_router.get("/task-readmes/{readme_id}")
async def get_task_readme_by_id(
    readme_id: int,
    db: Session = Depends(get_db),
):
    """
    æ ¹æ®README IDè·å–READMEè¯¦ç»†ä¿¡æ¯

    Args:
        readme_id: README ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«READMEè¯¦ç»†ä¿¡æ¯
    """
    try:
        # è·å–READMEä¿¡æ¯
        result = TaskReadmeService.get_task_readme_by_id(readme_id, db)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        if not result.get("readme"):
            return JSONResponse(status_code=404, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–READMEä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "readme_id": readme_id,
                "error": str(e),
            },
        )


@repository_router.get("/task-readmes/by-task/{task_id}")
async def get_task_readme_by_task_id(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    æ ¹æ®ä»»åŠ¡IDè·å–READMEä¿¡æ¯

    Args:
        task_id: ä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«READMEä¿¡æ¯
    """
    try:
        # è·å–READMEä¿¡æ¯
        result = TaskReadmeService.get_task_readme_by_task_id(task_id, db)

        if result["status"] == "error":
            return JSONResponse(status_code=500, content=result)

        # å¦‚æœæ²¡æœ‰ READMEï¼Œè¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯ 404
        if not result.get("readme"):
            return JSONResponse(status_code=200, content={
                "status": "success",
                "message": "è¯¥ä»»åŠ¡æš‚æ— READMEæ•°æ®",
                "task_id": task_id,
                "readme": None
            })

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "è·å–READMEä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "task_id": task_id,
                "error": str(e),
            },
        )


@repository_router.put("/task-readmes/{readme_id}")
async def update_task_readme(
    readme_id: int,
    readme_data: TaskReadmeUpdate,
    db: Session = Depends(get_db),
):
    """
    æ›´æ–°READMEä¿¡æ¯

    Args:
        readme_id: README ID
        readme_data: READMEæ›´æ–°æ•°æ®
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«æ›´æ–°åçš„READMEä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸ï¼Œæ’é™¤Noneå€¼
        data_dict = readme_data.model_dump(exclude_none=True)

        if not data_dict:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ",
                    "readme_id": readme_id,
                },
            )

        # æ›´æ–°README
        result = TaskReadmeService.update_task_readme(readme_id, data_dict, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=400, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "æ›´æ–°READMEæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "readme_id": readme_id,
                "error": str(e),
            },
        )


@repository_router.delete("/task-readmes/{readme_id}")
async def delete_task_readme(
    readme_id: int,
    db: Session = Depends(get_db),
):
    """
    åˆ é™¤README

    Args:
        readme_id: README ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«åˆ é™¤ç»“æœ
    """
    try:
        # åˆ é™¤README
        result = TaskReadmeService.delete_task_readme(readme_id, db)

        if result["status"] == "error":
            if "æœªæ‰¾åˆ°" in result["message"]:
                return JSONResponse(status_code=404, content=result)
            else:
                return JSONResponse(status_code=500, content=result)

        return JSONResponse(status_code=200, content=result)

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "åˆ é™¤READMEæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "readme_id": readme_id,
                "error": str(e),
            },
        )


@repository_router.post("/upload/compress-and-upload/{md5_folder_name}")
async def compress_and_upload_folder(
    md5_folder_name: str,
    db: Session = Depends(get_db),
):
    """
    å°†æŒ‡å®šmd5æ–‡ä»¶å¤¹å‹ç¼©æˆzipæ–‡ä»¶å¹¶ä¸Šä¼ åˆ°README APIæœåŠ¡

    Args:
        md5_folder_name: md5æ–‡ä»¶å¤¹åç§°
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«å‹ç¼©å’Œä¸Šä¼ ç»“æœ
    """
    try:
        from config import Settings
        import tempfile

        # æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
        folder_path = os.path.join(Settings.LOCAL_REPO_PATH, md5_folder_name)

        if not os.path.exists(folder_path):
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}"
                }
            )

        # åˆ›å»ºä¸´æ—¶zipæ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=f"_{md5_folder_name}.zip", delete=False) as temp_file:
            zip_path = temp_file.name

        # å‹ç¼©æ–‡ä»¶å¤¹
        compress_success = UploadService.create_zip_from_folder(folder_path, zip_path)

        if not compress_success:
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": "å‹ç¼©æ–‡ä»¶å¤¹å¤±è´¥"
                }
            )

        # ä¸Šä¼ åˆ°README API
        upload_result = await UploadService.upload_zip_to_readme_api(
            zip_path,
            Settings.README_API_BASE_URL
        )



        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(zip_path)
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        if upload_result["success"]:
            # è‡ªåŠ¨è§¦å‘åˆ†æä»»åŠ¡ï¼ˆå¸¦å»é‡æ£€æŸ¥ï¼‰
            try:
                from tasks import run_analysis_task
                from models import AnalysisTask, Repository

                # æŸ¥æ‰¾å¯¹åº”çš„ä»“åº“å’Œä»»åŠ¡
                repo = db.query(Repository).filter(Repository.local_path.like(f"%{md5_folder_name}%")).first()
                if repo:
                    # âœ… å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼ˆåªæ£€æŸ¥ running çŠ¶æ€ï¼Œä¸æ£€æŸ¥ pendingï¼‰
                    running_task = db.query(AnalysisTask).filter(
                        AnalysisTask.repository_id == repo.id,
                        AnalysisTask.status == 'running'
                    ).first()

                    if running_task:
                        logger.info(f"âš ï¸ ä»“åº“ {repo.id} å·²æœ‰ä»»åŠ¡ {running_task.id} æ­£åœ¨è¿è¡Œï¼ˆçŠ¶æ€: {running_task.status}ï¼‰ï¼Œè·³è¿‡è‡ªåŠ¨è§¦å‘")
                    else:
                        # æŸ¥æ‰¾æœ€æ–°çš„pendingä»»åŠ¡
                        task = db.query(AnalysisTask).filter(
                            AnalysisTask.repository_id == repo.id,
                            AnalysisTask.status == 'pending'
                        ).order_by(AnalysisTask.id.desc()).first()

                        if task:
                            # æäº¤Celeryä»»åŠ¡
                            celery_task = run_analysis_task.delay(
                                task_id=task.id,
                                external_file_path=repo.local_path
                            )
                            logger.info(f"âœ… è‡ªåŠ¨è§¦å‘åˆ†æä»»åŠ¡: ä»»åŠ¡ID {task.id}, Celeryä»»åŠ¡ID: {celery_task.id}")
            except Exception as e:
                logger.error(f"è‡ªåŠ¨è§¦å‘åˆ†æä»»åŠ¡å¤±è´¥: {e}")

            return JSONResponse(
                status_code=200,
                content={
                    "status": "success",
                    "message": "å‹ç¼©å’Œä¸Šä¼ æˆåŠŸ",
                    "md5_folder_name": md5_folder_name,
                    "upload_result": upload_result["data"]
                }
            )
        else:
            return JSONResponse(
                status_code=500,
                content={
                    "status": "error",
                    "message": f"ä¸Šä¼ å¤±è´¥: {upload_result['message']}",
                    "md5_folder_name": md5_folder_name
                }
            )

    except Exception as e:
        logger.error(f"å‹ç¼©å’Œä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "å‹ç¼©å’Œä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯",
                "md5_folder_name": md5_folder_name,
                "error": str(e)
            }
        )


@repository_router.get("/analysis-tasks/{task_id}/mermaid-diagrams")
async def get_mermaid_diagrams(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    è·å–æŒ‡å®šåˆ†æä»»åŠ¡çš„ Mermaid å›¾è¡¨

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å« Mermaid æ ¼å¼çš„ç±»å›¾ã€ä¾èµ–å›¾å’Œæµç¨‹å›¾
    """
    try:
        from utils.mermaid_generator import MermaidGenerator
        from models import AnalysisItem

        # æŸ¥è¯¢åˆ†æä»»åŠ¡
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"åˆ†æä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
                }
            )

        # è·å–æ‰€æœ‰æ–‡ä»¶åˆ†æï¼ˆé€šè¿‡ task_idï¼‰
        file_analyses = db.query(FileAnalysis).filter(
            FileAnalysis.task_id == task_id
        ).all()

        if not file_analyses:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": "æœªæ‰¾åˆ°æ–‡ä»¶åˆ†æç»“æœ"
                }
            )

        # è·å–æ‰€æœ‰åˆ†æé¡¹
        analysis_items = []
        file_analyses_data = []

        for file_analysis in file_analyses:
            # è·å–è¯¥æ–‡ä»¶çš„æ‰€æœ‰åˆ†æé¡¹
            items = db.query(AnalysisItem).filter(
                AnalysisItem.file_analysis_id == file_analysis.id
            ).all()

            for item in items:
                analysis_items.append(item.to_dict())

            # æ”¶é›†æ–‡ä»¶åˆ†ææ•°æ®ï¼ˆç”¨äºä¾èµ–å›¾ï¼‰
            file_analyses_data.append({
                "file_path": file_analysis.file_path,
                "dependencies": []  # TODO: ä»ä»£ç ä¸­æå–ä¾èµ–å…³ç³»
            })

        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        diagrams = MermaidGenerator.generate_all_diagrams(
            analysis_items=analysis_items,
            file_analyses=file_analyses_data
        )

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "task_id": task_id,
                "diagrams": diagrams,
                "stats": {
                    "total_items": len(analysis_items),
                    "total_files": len(file_analyses),
                    "diagram_count": len(diagrams)
                }
            }
        )

    except Exception as e:
        logger.error(f"ç”Ÿæˆ Mermaid å›¾è¡¨å¤±è´¥: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"ç”Ÿæˆ Mermaid å›¾è¡¨å¤±è´¥: {str(e)}"
            }
        )


@repository_router.get("/analysis-tasks/{task_id}/quality-report")
async def get_quality_report(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    è·å–æŒ‡å®šåˆ†æä»»åŠ¡çš„ä»£ç è´¨é‡æŠ¥å‘Š

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«ä»£ç è´¨é‡åˆ†æç»“æœ
    """
    try:
        from utils.code_quality_analyzer import CodeQualityAnalyzer

        # æŸ¥è¯¢åˆ†æä»»åŠ¡
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"åˆ†æä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
                }
            )

        # è·å–æ‰€æœ‰æ–‡ä»¶åˆ†æ
        file_analyses = db.query(FileAnalysis).filter(
            FileAnalysis.task_id == task_id
        ).all()

        if not file_analyses:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": "æœªæ‰¾åˆ°æ–‡ä»¶åˆ†æç»“æœ"
                }
            )

        # åˆ†ææ¯ä¸ªæ–‡ä»¶çš„ä»£ç è´¨é‡
        file_quality_results = []
        total_score = 0
        grade_counts = {"A": 0, "B": 0, "C": 0, "D": 0, "F": 0}
        language_stats = {}

        for file_analysis in file_analyses:
            # åªåˆ†ææœ‰ä»£ç å†…å®¹çš„æ–‡ä»¶
            if not file_analysis.code_content:
                continue

            # åˆ†æä»£ç è´¨é‡
            quality_result = CodeQualityAnalyzer.analyze_file_quality(
                file_path=file_analysis.file_path,
                code=file_analysis.code_content,
                language=file_analysis.language or "python"
            )

            # åªä¿ç•™æ”¯æŒçš„è¯­è¨€
            if not quality_result.get("supported"):
                continue

            # ç»Ÿè®¡
            if "quality_score" in quality_result:
                total_score += quality_result["quality_score"]
                grade = quality_result.get("grade", "F")
                grade_counts[grade] = grade_counts.get(grade, 0) + 1

            # è¯­è¨€ç»Ÿè®¡
            lang = quality_result.get("language", "unknown")
            if lang not in language_stats:
                language_stats[lang] = {"count": 0, "total_score": 0}
            language_stats[lang]["count"] += 1
            language_stats[lang]["total_score"] += quality_result.get("quality_score", 0)

            # ç®€åŒ–ç»“æœï¼ˆä¸åŒ…å«è¯¦ç»†çš„å‡½æ•°åˆ—è¡¨ï¼‰
            simplified_result = {
                "file_path": quality_result["file_path"],
                "language": quality_result["language"],
                "quality_score": quality_result.get("quality_score", 0),
                "grade": quality_result.get("grade", "F"),
                "complexity_avg": quality_result.get("complexity", {}).get("average", 0),
                "maintainability_score": quality_result.get("maintainability", {}).get("score", 0),
                "comment_ratio": quality_result.get("comment_ratio", {}).get("ratio", 0),
            }

            file_quality_results.append(simplified_result)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        analyzed_files = len(file_quality_results)
        if analyzed_files == 0:
            return JSONResponse(
                status_code=200,
                content={
                    "status": "success",
                    "task_id": task_id,
                    "message": "æ²¡æœ‰å¯åˆ†æçš„æ–‡ä»¶ï¼ˆå¯èƒ½ä¸æ”¯æŒè¯¥è¯­è¨€ï¼‰",
                    "summary": {
                        "total_files": len(file_analyses),
                        "analyzed_files": 0
                    }
                }
            )

        average_score = total_score / analyzed_files

        # è®¡ç®—è¯­è¨€å¹³å‡åˆ†
        for lang, stats in language_stats.items():
            if stats["count"] > 0:
                stats["average_score"] = round(stats["total_score"] / stats["count"], 2)

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "task_id": task_id,
                "summary": {
                    "total_files": len(file_analyses),
                    "analyzed_files": analyzed_files,
                    "average_score": round(average_score, 2),
                    "overall_grade": CodeQualityAnalyzer._get_quality_grade(average_score),
                    "grade_distribution": grade_counts,
                    "language_stats": language_stats
                },
                "files": file_quality_results[:50]  # é™åˆ¶è¿”å›å‰ 50 ä¸ªæ–‡ä»¶
            }
        )

    except Exception as e:
        logger.error(f"ç”Ÿæˆä»£ç è´¨é‡æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"ç”Ÿæˆä»£ç è´¨é‡æŠ¥å‘Šå¤±è´¥: {str(e)}"
            }
        )


@repository_router.get("/analysis-tasks/{task_id}/dependencies")
async def get_dependencies_analysis(
    task_id: int,
    db: Session = Depends(get_db),
):
    """
    è·å–æŒ‡å®šåˆ†æä»»åŠ¡çš„ä¾èµ–å…³ç³»åˆ†æ

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        JSONå“åº”åŒ…å«ä¾èµ–å…³ç³»åˆ†æç»“æœ
    """
    try:
        from utils.dependency_analyzer import DependencyAnalyzer
        import json as json_lib

        # æŸ¥è¯¢åˆ†æä»»åŠ¡
        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
        if not task:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": f"åˆ†æä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
                }
            )

        # è·å–æ‰€æœ‰æ–‡ä»¶åˆ†æ
        file_analyses = db.query(FileAnalysis).filter(
            FileAnalysis.task_id == task_id
        ).all()

        if not file_analyses:
            return JSONResponse(
                status_code=404,
                content={
                    "status": "error",
                    "message": "æœªæ‰¾åˆ°æ–‡ä»¶åˆ†æç»“æœ"
                }
            )

        # æå–æ¯ä¸ªæ–‡ä»¶çš„ä¾èµ–å…³ç³»
        file_dependencies = {}

        for file_analysis in file_analyses:
            # å¦‚æœæ•°æ®åº“ä¸­å·²ç»å­˜å‚¨äº†ä¾èµ–å…³ç³»ï¼Œç›´æ¥ä½¿ç”¨
            if file_analysis.dependencies:
                try:
                    deps = json_lib.loads(file_analysis.dependencies)
                    if isinstance(deps, list):
                        file_dependencies[file_analysis.file_path] = deps
                    continue
                except:
                    pass

            # å¦åˆ™ä»ä»£ç ä¸­æå–
            if file_analysis.code_content:
                deps = DependencyAnalyzer.extract_dependencies(
                    code=file_analysis.code_content,
                    language=file_analysis.language or "python"
                )
                file_dependencies[file_analysis.file_path] = deps

                # æ›´æ–°æ•°æ®åº“
                try:
                    file_analysis.dependencies = json_lib.dumps(deps)
                    db.commit()
                except Exception as e:
                    logger.warning(f"æ›´æ–°ä¾èµ–å…³ç³»å¤±è´¥: {e}")
                    db.rollback()

        # åˆ†æä¾èµ–å…³ç³»
        summary = DependencyAnalyzer.analyze_dependencies_summary(file_dependencies)

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "task_id": task_id,
                "summary": summary,
                "file_dependencies": {
                    k: v for k, v in list(file_dependencies.items())[:50]  # é™åˆ¶è¿”å›å‰ 50 ä¸ª
                }
            }
        )

    except Exception as e:
        logger.error(f"ä¾èµ–å…³ç³»åˆ†æå¤±è´¥: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"ä¾èµ–å…³ç³»åˆ†æå¤±è´¥: {str(e)}"
            }
        )


@repository_router.post("/repositories/{repository_id}/init-claude-session")
async def init_claude_session(
    repository_id: int,
    db: Session = Depends(get_db)
):
    """
    åˆå§‹åŒ–ä»“åº“çš„ Claude AI ä¼šè¯

    å¦‚æœä»“åº“å·²æœ‰ claude_session_idï¼Œåˆ™ç›´æ¥è¿”å›
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™æ‰“åŒ…ä»£ç å¹¶ä¸Šä¼ åˆ° claude-agent-sdk åˆ›å»ºæ–°ä¼šè¯
    """
    try:
        # è·å–ä»“åº“ä¿¡æ¯
        repository = db.query(Repository).filter(Repository.id == repository_id).first()
        if not repository:
            raise HTTPException(status_code=404, detail="ä»“åº“ä¸å­˜åœ¨")

        # å¦‚æœå·²æœ‰ session_idï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
        if repository.claude_session_id:
            # éªŒè¯ session æ˜¯å¦å­˜åœ¨
            claude_api_url = os.getenv("CLAUDE_CHAT_API_BASE_URL", "http://localhost:8003")
            test_response = requests.post(
                f"{claude_api_url}/chat/{repository.claude_session_id}",
                json={"query": "test", "conversation_id": None},
                timeout=5
            )

            if test_response.status_code != 404:
                # Session æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
                return JSONResponse(
                    status_code=200,
                    content={
                        "status": "success",
                        "message": "Claude session å·²å­˜åœ¨",
                        "session_id": repository.claude_session_id
                    }
                )

        # Session ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œåˆ›å»ºæ–°çš„
        local_path = Path(repository.local_path)
        if not local_path.exists():
            raise HTTPException(status_code=404, detail=f"ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {repository.local_path}")

        # åˆ›å»ºä¸´æ—¶ zip æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as tmp_file:
            zip_path = tmp_file.name

        try:
            # æ‰“åŒ…ä»£ç åº“
            logger.info(f"æ­£åœ¨æ‰“åŒ…ä»£ç åº“: {local_path}")
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(local_path):
                    # æ’é™¤å¸¸è§çš„ä¸éœ€è¦çš„ç›®å½•
                    dirs[:] = [d for d in dirs if d not in {
                        '.git', '__pycache__', 'node_modules', '.venv', 'venv',
                        '.idea', '.vscode', 'build', 'dist', '.next'
                    }]

                    for file in files:
                        file_path = Path(root) / file
                        arcname = file_path.relative_to(local_path)
                        zipf.write(file_path, arcname)

            # ä¸Šä¼ åˆ° claude-agent-sdk
            logger.info(f"æ­£åœ¨ä¸Šä¼ åˆ° claude-agent-sdk")
            claude_api_url = os.getenv("CLAUDE_CHAT_API_BASE_URL", "http://localhost:8003")

            with open(zip_path, 'rb') as f:
                files = {'file': (f'{repository.name}.zip', f, 'application/zip')}
                response = requests.post(
                    f"{claude_api_url}/session/create",
                    files=files,
                    timeout=60
                )

            if response.status_code != 201:
                error_detail = response.json().get('detail', 'Unknown error')
                raise HTTPException(
                    status_code=500,
                    detail=f"åˆ›å»º Claude session å¤±è´¥: {error_detail}"
                )

            # è·å– session_id
            result = response.json()
            session_id = result.get('session_id')

            # æ›´æ–°æ•°æ®åº“
            repository.claude_session_id = session_id
            db.commit()

            logger.info(f"Claude session åˆ›å»ºæˆåŠŸ: {session_id}")

            return JSONResponse(
                status_code=200,
                content={
                    "status": "success",
                    "message": "Claude session åˆ›å»ºæˆåŠŸ",
                    "session_id": session_id
                }
            )

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(zip_path):
                os.unlink(zip_path)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆå§‹åŒ– Claude session å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"åˆå§‹åŒ– Claude session å¤±è´¥: {str(e)}"
        )


# å¯¼å‡ºè·¯ç”±å™¨
__all__ = ["repository_router", "analysis_router"]
