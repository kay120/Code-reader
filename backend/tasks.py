"""
Celeryå¼‚æ­¥ä»»åŠ¡
ç”¨äºå¤„ç†è€—æ—¶çš„åå°ä»»åŠ¡,é¿å…é˜»å¡APIè¯·æ±‚
"""
import asyncio
import logging
import sys
from pathlib import Path

# ç¡®ä¿backendç›®å½•åœ¨Pythonè·¯å¾„ä¸­(Celeryå­è¿›ç¨‹éœ€è¦)
backend_dir = Path(__file__).parent.absolute()
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

from celery_app import celery_app

logger = logging.getLogger(__name__)


@celery_app.task(name="tasks.run_analysis_task", bind=True)
def run_analysis_task(self, task_id: int, external_file_path: str):
    """
    Celeryå¼‚æ­¥ä»»åŠ¡: è¿è¡Œå®Œæ•´çš„åˆ†æä»»åŠ¡

    è¿™æ˜¯ä¸»è¦çš„åå°ä»»åŠ¡,åŒ…å«æ‰€æœ‰4ä¸ªæ­¥éª¤:
    - æ­¥éª¤0: æ‰«æä»£ç æ–‡ä»¶
    - æ­¥éª¤1: åˆ›å»ºçŸ¥è¯†åº“
    - æ­¥éª¤2: åˆ†ææ•°æ®æ¨¡å‹
    - æ­¥éª¤3: ç”Ÿæˆæ–‡æ¡£ç»“æ„

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        external_file_path: å¤–éƒ¨æ–‡ä»¶è·¯å¾„

    Returns:
        dict: ä»»åŠ¡æ‰§è¡Œç»“æœ
    """
    try:
        logger.info(f"ğŸš€ Celeryä»»åŠ¡å¼€å§‹: è¿è¡Œåˆ†æä»»åŠ¡ {task_id}")

        # å¯¼å…¥run_taskå‡½æ•°(å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–)
        import sys
        from pathlib import Path
        # ç¡®ä¿backendç›®å½•åœ¨Pythonè·¯å¾„ä¸­
        backend_dir = Path(__file__).parent.absolute()
        if str(backend_dir) not in sys.path:
            sys.path.insert(0, str(backend_dir))

        from service.task_service import run_task

        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            result = loop.run_until_complete(
                run_task(task_id=task_id, external_file_path=external_file_path)
            )

            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if result.get("status") == "success":
                logger.info(f"âœ… Celeryä»»åŠ¡æˆåŠŸ: åˆ†æä»»åŠ¡ {task_id} å®Œæˆ")
                return {
                    "status": "success",
                    "task_id": task_id,
                    "message": result.get("message", "ä»»åŠ¡æ‰§è¡Œå®Œæˆ"),
                }
            else:
                logger.error(f"âŒ Celeryä»»åŠ¡å¤±è´¥: åˆ†æä»»åŠ¡ {task_id} å¤±è´¥ - {result}")
                return {
                    "status": "failed",
                    "task_id": task_id,
                    "error": result.get("message", "æœªçŸ¥é”™è¯¯"),
                }
        finally:
            loop.close()

    except Exception as e:
        logger.error(f"âŒ Celeryä»»åŠ¡å¼‚å¸¸: åˆ†æä»»åŠ¡ {task_id} å‡ºé”™ - {str(e)}", exc_info=True)
        # é‡è¯•ä»»åŠ¡(æœ€å¤š2æ¬¡,æ¯æ¬¡å»¶è¿Ÿ120ç§’)
        raise self.retry(exc=e, countdown=120, max_retries=2)


@celery_app.task(name="tasks.analyze_single_file_task", bind=True)
def analyze_single_file_task(self, task_id: int, file_id: int, vectorstore_index: str):
    """
    Celeryå¼‚æ­¥ä»»åŠ¡: åˆ†æå•ä¸ªæ–‡ä»¶çš„æ•°æ®æ¨¡å‹

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        file_id: æ–‡ä»¶ID
        vectorstore_index: å‘é‡å­˜å‚¨ç´¢å¼•åç§°

    Returns:
        dict: åˆ†æç»“æœ
    """
    try:
        logger.info(f"ğŸš€ Celeryä»»åŠ¡å¼€å§‹: åˆ†ææ–‡ä»¶ {file_id} (ä»»åŠ¡ID: {task_id})")

        # æ›´æ–°ä»»åŠ¡çš„current_fileå­—æ®µ
        from database import SessionLocal
        from models import AnalysisTask, FileAnalysis

        db = SessionLocal()
        try:
            # è·å–æ–‡ä»¶è·¯å¾„
            file_analysis = db.query(FileAnalysis).filter(FileAnalysis.id == file_id).first()
            if file_analysis:
                # æ›´æ–°ä»»åŠ¡çš„å½“å‰å¤„ç†æ–‡ä»¶
                task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                if task:
                    task.current_file = file_analysis.file_path
                    db.commit()
                    logger.info(f"ğŸ“ æ›´æ–°ä»»åŠ¡ {task_id} å½“å‰å¤„ç†æ–‡ä»¶: {file_analysis.file_path}")
        except Exception as e:
            logger.warning(f"æ›´æ–°current_fileå¤±è´¥: {str(e)}")
            db.rollback()
        finally:
            db.close()

        # å¯¼å…¥flowå‡½æ•°(å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–)
        from src.flows.web_flow import analyze_single_file_data_model

        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            result = loop.run_until_complete(
                analyze_single_file_data_model(
                    task_id=task_id,
                    file_id=file_id,
                    vectorstore_index=vectorstore_index
                )
            )

            # æ£€æŸ¥flowæ‰§è¡Œç»“æœ
            if result.get("status") == "completed":
                analysis_items_count = result.get("analysis_items_count", 0)
                logger.info(f"âœ… Celeryä»»åŠ¡æˆåŠŸ: æ–‡ä»¶ {file_id} åˆ†æå®Œæˆ,åˆ›å»ºäº† {analysis_items_count} ä¸ªåˆ†æé¡¹")

                # ========== æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½å·²åˆ†æå®Œæˆ ==========
                db = SessionLocal()
                try:
                    # æŸ¥è¯¢ä»»åŠ¡ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åˆ†æè®°å½•
                    all_files = db.query(FileAnalysis).filter(FileAnalysis.task_id == task_id).all()
                    total_files = len(all_files)
                    completed_files = sum(1 for f in all_files if f.status == 'success')
                    failed_files = sum(1 for f in all_files if f.status == 'failed')
                    pending_files = sum(1 for f in all_files if f.status == 'pending')

                    logger.info(f"ğŸ“Š ä»»åŠ¡ {task_id} è¿›åº¦: {completed_files}/{total_files} å®Œæˆ, {failed_files} å¤±è´¥, {pending_files} å¾…å¤„ç†")

                    # å¦‚æœæ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰ï¼Œè§¦å‘æ­¥éª¤ 3
                    if pending_files == 0:
                        logger.info(f"ğŸ‰ ä»»åŠ¡ {task_id} æ‰€æœ‰æ–‡ä»¶åˆ†æå®Œæˆï¼å‡†å¤‡è§¦å‘æ­¥éª¤ 3ï¼ˆç”Ÿæˆæ–‡æ¡£ï¼‰")

                        # è·å–ä»»åŠ¡ä¿¡æ¯
                        task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                        if task:
                            # è·å–ä»“åº“ä¿¡æ¯
                            from models import Repository
                            repository = db.query(Repository).filter(Repository.id == task.repository_id).first()
                            if repository:
                                external_file_path = repository.local_path

                                # å¼‚æ­¥è§¦å‘æ­¥éª¤ 3
                                logger.info(f"ğŸš€ è§¦å‘æ­¥éª¤ 3: ç”Ÿæˆæ–‡æ¡£ç»“æ„")
                                from tasks import generate_document_task
                                generate_document_task.delay(task_id, external_file_path)
                                logger.info(f"âœ… æ­¥éª¤ 3 å·²æäº¤åˆ°åå°é˜Ÿåˆ—")
                except Exception as e:
                    logger.error(f"æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€å¤±è´¥: {str(e)}")
                finally:
                    db.close()

                return {
                    "status": "success",
                    "file_id": file_id,
                    "analysis_items_count": analysis_items_count,
                }
            else:
                logger.error(f"âŒ Celeryä»»åŠ¡å¤±è´¥: æ–‡ä»¶ {file_id} åˆ†æå¤±è´¥ - {result}")
                return {
                    "status": "failed",
                    "file_id": file_id,
                    "error": str(result),
                }
        finally:
            loop.close()

    except Exception as e:
        logger.error(f"âŒ Celeryä»»åŠ¡å¼‚å¸¸: æ–‡ä»¶ {file_id} åˆ†æå‡ºé”™ - {str(e)}", exc_info=True)
        # é‡è¯•ä»»åŠ¡(æœ€å¤š3æ¬¡,æ¯æ¬¡å»¶è¿Ÿ60ç§’)
        raise self.retry(exc=e, countdown=60, max_retries=3)


@celery_app.task(name="tasks.generate_document_task", bind=True)
def generate_document_task(self, task_id: int, external_file_path: str):
    """
    Celeryå¼‚æ­¥ä»»åŠ¡: ç”Ÿæˆæ–‡æ¡£ç»“æ„ï¼ˆæ­¥éª¤ 3ï¼‰

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        external_file_path: å¤–éƒ¨æ–‡ä»¶è·¯å¾„

    Returns:
        dict: ä»»åŠ¡æ‰§è¡Œç»“æœ
    """
    try:
        logger.info(f"ğŸš€ Celeryä»»åŠ¡å¼€å§‹: ç”Ÿæˆæ–‡æ¡£ç»“æ„ (ä»»åŠ¡ID: {task_id})")

        # å¯¼å…¥å‡½æ•°
        from service.task_service import execute_step_3_generate_document_structure
        from database import SessionLocal
        from models import AnalysisTask, Repository

        # è·å–ä»»åŠ¡å’Œä»“åº“ä¿¡æ¯
        db = SessionLocal()
        try:
            task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
            if not task:
                logger.error(f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}")
                return {"status": "failed", "error": "ä»»åŠ¡ä¸å­˜åœ¨"}

            repository = db.query(Repository).filter(Repository.id == task.repository_id).first()
            if not repository:
                logger.error(f"æœªæ‰¾åˆ°ä»“åº“ {task.repository_id}")
                return {"status": "failed", "error": "ä»“åº“ä¸å­˜åœ¨"}

            repo_info = {
                "id": repository.id,
                "name": repository.name,
                "local_path": repository.local_path,
            }
        finally:
            db.close()

        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            result = loop.run_until_complete(
                execute_step_3_generate_document_structure(task_id, external_file_path, repo_info)
            )

            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if result.get("success"):
                logger.info(f"âœ… Celeryä»»åŠ¡æˆåŠŸ: æ–‡æ¡£ç”Ÿæˆå®Œæˆ (ä»»åŠ¡ID: {task_id})")

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                db = SessionLocal()
                try:
                    task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                    if task:
                        task.status = "completed"
                        from datetime import datetime
                        task.end_time = datetime.now()
                        task.progress_percentage = 100
                        task.current_file = None
                        db.commit()
                        logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå®Œæˆ")
                finally:
                    db.close()

                return {
                    "status": "success",
                    "task_id": task_id,
                    "message": "æ–‡æ¡£ç”Ÿæˆå®Œæˆ",
                }
            else:
                logger.warning(f"âš ï¸ Celeryä»»åŠ¡å¤±è´¥: æ–‡æ¡£ç”Ÿæˆå¤±è´¥ (ä»»åŠ¡ID: {task_id}) - {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                # æ–‡æ¡£ç”Ÿæˆå¤±è´¥ä¸å½±å“æ•´ä½“ä»»åŠ¡ï¼Œä»ç„¶æ ‡è®°ä¸ºå®Œæˆ
                db = SessionLocal()
                try:
                    task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
                    if task:
                        task.status = "completed"
                        from datetime import datetime
                        task.end_time = datetime.now()
                        task.progress_percentage = 100
                        task.current_file = None
                        db.commit()
                        logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå®Œæˆï¼ˆæ–‡æ¡£ç”Ÿæˆå¤±è´¥ä½†ä¸å½±å“æ•´ä½“ï¼‰")
                finally:
                    db.close()

                return {
                    "status": "success",
                    "task_id": task_id,
                    "message": "æ–‡ä»¶åˆ†æå®Œæˆï¼Œä½†æ–‡æ¡£ç”Ÿæˆå¤±è´¥",
                }
        finally:
            loop.close()

    except Exception as e:
        logger.error(f"âŒ Celeryä»»åŠ¡å¼‚å¸¸: æ–‡æ¡£ç”Ÿæˆå‡ºé”™ (ä»»åŠ¡ID: {task_id}) - {str(e)}", exc_info=True)
        # ä¸é‡è¯•ï¼Œç›´æ¥æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
        db = SessionLocal()
        try:
            task = db.query(AnalysisTask).filter(AnalysisTask.id == task_id).first()
            if task:
                task.status = "completed"
                from datetime import datetime
                task.end_time = datetime.now()
                task.progress_percentage = 100
                task.current_file = None
                db.commit()
                logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå®Œæˆï¼ˆæ–‡æ¡£ç”Ÿæˆå¼‚å¸¸ä½†ä¸å½±å“æ•´ä½“ï¼‰")
        finally:
            db.close()

        return {
            "status": "failed",
            "task_id": task_id,
            "error": str(e),
        }


@celery_app.task(name="tasks.batch_analyze_files_task")
def batch_analyze_files_task(task_id: int, file_ids: list, vectorstore_index: str):
    """
    Celeryå¼‚æ­¥ä»»åŠ¡: æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶

    Args:
        task_id: åˆ†æä»»åŠ¡ID
        file_ids: æ–‡ä»¶IDåˆ—è¡¨
        vectorstore_index: å‘é‡å­˜å‚¨ç´¢å¼•åç§°
        
    Returns:
        dict: æ‰¹é‡åˆ†æç»“æœ
    """
    try:
        logger.info(f"ğŸš€ Celeryæ‰¹é‡ä»»åŠ¡å¼€å§‹: åˆ†æ {len(file_ids)} ä¸ªæ–‡ä»¶ (ä»»åŠ¡ID: {task_id})")
        
        results = []
        for file_id in file_ids:
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡
            result = analyze_single_file_task.delay(task_id, file_id, vectorstore_index)
            results.append({
                "file_id": file_id,
                "celery_task_id": result.id,
            })
        
        logger.info(f"âœ… Celeryæ‰¹é‡ä»»åŠ¡å·²åˆ†å‘: {len(results)} ä¸ªå­ä»»åŠ¡")
        return {
            "status": "dispatched",
            "task_id": task_id,
            "total_files": len(file_ids),
            "subtasks": results,
        }
        
    except Exception as e:
        logger.error(f"âŒ Celeryæ‰¹é‡ä»»åŠ¡å¼‚å¸¸: {str(e)}", exc_info=True)
        return {
            "status": "failed",
            "task_id": task_id,
            "error": str(e),
        }

